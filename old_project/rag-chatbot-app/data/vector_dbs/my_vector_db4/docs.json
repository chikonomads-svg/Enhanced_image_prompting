[{"page_content": "Agentic AI: A Comprehensive Survey of\nArchitectures, Applications, and Future\nDirections\nMohamad Abou Ali1, 3, 4 and Fadi Dornaika*1, 2\n1University of the Basque Country, 2IKERBASQUE, 3Lebanese\nInternational University (LIU), 4The International University of Beirut,\nmohamad.abouali01@liu.edu.lb, fadi.dornaika@ehu.eus\nAbstract\nAgentic AI represents a transformative shift in artificial intelligence, but its\nrapid advancement has led to a fragmented understanding, often conflating mod-\nern neural systems with outdated symbolic models—a practice known ascon-\nceptual retrofitting. This survey cuts through this confusion by introducing a\nnoveldual-paradigm frameworkthat categorizes agentic systems into two dis-\ntinct lineages: theSymbolic/Classical(relying on algorithmic planning and per-\nsistent state) and theNeural/Generative(leveraging stochastic generation and\nprompt-driven orchestration). Through a systematic PRISMA-based review of 90\nstudies (2018–2025), we provide a comprehensive anal", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 0}}, {"page_content": "t state) and theNeural/Generative(leveraging stochastic generation and\nprompt-driven orchestration). Through a systematic PRISMA-based review of 90\nstudies (2018–2025), we provide a comprehensive analysis structured around this\nframework across three dimensions: (1) the theoretical foundations and architec-\ntural principles defining each paradigm; (2) domain-specific implementations in\nhealthcare, finance, and robotics, demonstrating how application constraints dic-\ntate paradigm selection; and (3) paradigm-specific ethical and governance chal-\nlenges, revealing divergent risks and mitigation strategies. Our analysis reveals\nthat the choice of paradigm is strategic: symbolic systems dominate safety-critical\ndomains (e.g., healthcare), while neural systems prevail in adaptive, data-rich en-\nvironments (e.g., finance). Furthermore, we identify critical research gaps, includ-\ning a significant deficit in governance models for symbolic systems and a pressing\nneed for hybrid neuro-symbolic ", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 1}}, {"page_content": "\nvironments (e.g., finance). Furthermore, we identify critical research gaps, includ-\ning a significant deficit in governance models for symbolic systems and a pressing\nneed for hybrid neuro-symbolic architectures. The findings culminate in a strate-\ngic roadmap arguing that the future of Agentic AI lies not in the dominance of one\nparadigm, but in their intentional integration to create systems that are bothadapt-\nableandreliable. This work provides the essential conceptual toolkit to guide\nfuture research, development, and policy toward robust and trustworthy hybrid in-\ntelligent systems.\nKeywords—Agentic AI, artificial intelligence, systematic review, neural architectures, sym-\nbolic AI, multi-agent systems, AI governance, neuro-symbolic AI\n*Corresponding author\n1\narXiv:2510.25445v1  [cs.AI]  29 Oct 2025", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 2}}, {"page_content": "s.AI]  29 Oct 2025", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 3}}, {"page_content": "1 Introduction\nThe field of Artificial Intelligence (AI) is undergoing a paradigm shift from the development of\npassive, task-specific tools toward the engineering of autonomous systems that exhibit genuine\nagency. Modern agentic AI systems [1, 2] are defined by capabilities such as proactive planning,\ncontextual memory, sophisticated tool use, and the ability to adapt their behavior based on en-\nvironmental feedback. These systems operate not as mere solvers but as collaborative partners,\ncapable of dynamically perceiving complex environments, reasoning about abstract goals, and\norchestrating sequences of actions—either independently or as part of a sophisticated multi-agent\necosystem [3, 4].\nTo establish a precise conceptual foundation, we distinguish between the field’s core con-\ncepts. AnAI Agent(or aSingle-Agent System) is a self-contained autonomous system designed\nto accomplish a goal. It operates primarily in isolation, though it may interact with tools and\nAPIs. Its agency is ", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 0}}, {"page_content": " AnAI Agent(or aSingle-Agent System) is a self-contained autonomous system designed\nto accomplish a goal. It operates primarily in isolation, though it may interact with tools and\nAPIs. Its agency is defined by itsautonomy,proactivity, and its ability to complete a task from\nstart to finish independently.\nFor example, a single, powerfulLLM-based (Large Language Model-based)agent tasked\nwith “Write a full project proposal for a new mobile app” would autonomously break down the\ntask, conduct research, write the sections, and format the final document.\nIn contrast,Agentic AIis the broader field and architectural approach concerned with creat-\ning systems that exhibit agency. Crucially, this often involves the orchestration ofMulti-Agent\nSystems (MAS), where multiple specialized agents work together, coordinating and communicat-\ning to solve problems that are too complex for a single agent.\nFor example, an Agentic AI system designed for the same task would employ a team of\nspecialized agen", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 1}}, {"page_content": "gether, coordinating and communicat-\ning to solve problems that are too complex for a single agent.\nFor example, an Agentic AI system designed for the same task would employ a team of\nspecialized agents: aProject Manager Agentto break the goal into tasks, aResearcher Agentto\ngather market data, aWriter Agentto draft content, and aQuality Assurance Agentto review the\noutput. Their collaborative workflow is the embodiment of Agentic AI.\nIn summary, one can conceptualize anAI Agentas a single, sophisticated worker, while\nAgentic AIrepresents the principle of leveraging agency, frequently by architecting and manag-\ning an entire team of such workers.\nThis rapid evolution, however, has led to a fragmented and often anachronistic understanding\nof the field. A critical issue identified in prior reviews isconceptual retrofitting—the misapplica-\ntion of classical symbolic frameworks (e.g., Belief–Desire–Intention (BDI) [5],perceive–plan–act–reflect\n(PPAR)loops [6, 7]) to describe modern systems", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 2}}, {"page_content": "eviews isconceptual retrofitting—the misapplica-\ntion of classical symbolic frameworks (e.g., Belief–Desire–Intention (BDI) [5],perceive–plan–act–reflect\n(PPAR)loops [6, 7]) to describe modern systems built onlarge language models (LLMs)[8],\nwhich operate on fundamentally different principles of stochastic generation and prompt-driven\norchestration. This practice obscures the true operational mechanics of LLM-based agents [9,\n10, 11, 12] and creates a false sense of continuity between incompatible architectural paradigms,\nwhether applied to a single complex agent or a coordinated MAS.\nThis paper addresses these gaps by first establishing a clear historical context (Figure 1),\nwhich delineates the evolution of AI through five distinct but overlapping eras.\n2", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 3}}, {"page_content": "Figure 1: Historical Evolution of AI Paradigms: This timeline charts the key breakthroughs and eras in AI, from early symbolic systems to\nthe modern agentic era. It highlights the Transformer architecture as the pivotal enabling technology for large language models (LLMs),\nwhich in turn powered the generative AI revolution and provided the substrate for contemporary agentic systems.\n3", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 0}}, {"page_content": "TheSymbolic AI Era (1950s–1980s)[13] established the foundational ambition of artificial\nintelligence, grounded in logic and explicit human knowledge. This period was dominated by\nrule-based systems and expert systems such as MYCIN and DENDRAL [14], which operated\non carefully hand-crafted symbolic rules. Intelligence was conceived as a top-down, deductive\nprocess, representing the purest form of the symbolic paradigm.\nTheMachine Learning (ML) Era (1980s–2010s)[15, 16, 17] marked a pivotal shift away\nfrom hard-coded logic toward systems that could learn from data. While still heavily dependent\non human-engineered features, this period introduced statistical ML models such as Support\nVector Machines and decision trees, which powered applications ranging from classification to\nrecommendation. It was a transitional stage that moved the field away from pure symbolism but\nstill lacked the automated feature learning that would define subsequent eras.\nThe arrival of theDeep Learning Era (2010", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 0}}, {"page_content": ". It was a transitional stage that moved the field away from pure symbolism but\nstill lacked the automated feature learning that would define subsequent eras.\nThe arrival of theDeep Learning Era (2010s–Present)[18, 19, 20, 21, 22] was catalyzed by\nthe confluence of increased compute power and large datasets. Deep neural networks, including\nconvolutional and recurrent architectures, enabled systems to automatically learn hierarchical\nrepresentations from raw data. This era revolutionized pattern recognition in vision, speech, and\ntext, breaking longstanding barriers in perception. Yet, despite their power, these models largely\nfunctioned as sophisticated pattern classifiers rather than autonomous agents.\nOut of this foundation emerged theGenerative AI Era (2014–Present)[23, 24, 25, 26, 27],\nfueled by advances in generative modeling. Early breakthroughs such as Generative Adversarial\nNetworks were soon eclipsed by the introduction of the Transformer architecture in 2017, which\nenabled th", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 1}}, {"page_content": "\nfueled by advances in generative modeling. Early breakthroughs such as Generative Adversarial\nNetworks were soon eclipsed by the introduction of the Transformer architecture in 2017, which\nenabled the scaling of large language models (LLMs) such as GPT and BERT. These systems\nmoved beyond perception to generation, producing coherent text, code, and media. In doing\nso, they provided the essential substrate—a powerful, general-purpose statistical reasoner—that\nmade modern agentic AI feasible.\nFinally, theAgentic AI Era (2022–Present)represents the current frontier, where the gen-\nerative capabilities of LLMs are harnessed for action and autonomy. This era is characterized\nby the rise of AI agents [28, 29, 30] such as AutoGPT, which can pursue goals through planning\nand tool use. Increasingly, these agents evolve into multi-agent systems [31, 32, 33, 34, 35],\nexemplified by frameworks like CrewAI and AutoGen, where specialized roles and orchestrated\ncollaboration enable teams of agents t", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 2}}, {"page_content": "y, these agents evolve into multi-agent systems [31, 32, 33, 34, 35],\nexemplified by frameworks like CrewAI and AutoGen, where specialized roles and orchestrated\ncollaboration enable teams of agents to tackle complex problems. In contrast to the algorith-\nmic deliberation of the symbolic paradigm, this stage is defined by the neural paradigm, where\nagency emerges from the stochastic orchestration of generative models.\nThis chronological progression provides essential context but also reveals a critical concep-\ntual schism. The agentic AI era is not simply a linear descendant of symbolic AI but is instead\nbuilt upon a completely different architectural foundation. To address this, we introduce a novel\nconceptual framework (Figure 2) designed to prevent retrospective conflation by clearly distin-\nguishing the symbolic and neural lineages of agentic AI. This dual-axis taxonomy provides the\nunified lens necessary to rigorously analyze the field’s theoretical underpinnings, architectural\nin", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 3}}, {"page_content": "stin-\nguishing the symbolic and neural lineages of agentic AI. This dual-axis taxonomy provides the\nunified lens necessary to rigorously analyze the field’s theoretical underpinnings, architectural\ninnovations, and practical deployments.\nThe journey to modern agentic AI is best understood through its historical progression, as\ndetailed in Figure 1. This evolution moved from the deterministic, rule-based systems of the\nsymbolic era through the data-driven revolutions of machine learning and deep learning, culmi-\nnating in the transformative advent of large language models (LLMs) [36, 37] and generative\nAI.\nHowever, a chronological account is insufficient for analytical rigor. The central challenge\nin current discourse is the conceptual retrofitting of modern, neural agentic architectures into\nthe frameworks of the symbolic era. To resolve this, we propose a dual-paradigm taxonomy in\nFigure 2. This framework categorizes agentic systems along two independent dimensions: their\nArchitectura", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 4}}, {"page_content": "to\nthe frameworks of the symbolic era. To resolve this, we propose a dual-paradigm taxonomy in\nFigure 2. This framework categorizes agentic systems along two independent dimensions: their\nArchitectural Paradigm(Symbolic vs. Neural) and theirDegree of Agency & Coordination\n(Single-Agent vs. Multi-Agent). This model is designed not to show evolution, but to provide\n4", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 5}}, {"page_content": "a clear analytical structure for classification and comparison, ensuring systems are evaluated on\ntheir own operational terms.\nFigure 2: Conceptual Framework of Agentic AI’s Dual Lineages. This taxonomy re-\nsolves conceptual retrofitting by distinguishing the Symbolic/Classical lineage (left),\ndefined by algorithmic planning and persistent state, from the Neural/Generative lin-\neage (right), defined by stochastic generation and prompt-driven orchestration. While\nboth paradigms target similar applications, their underlying mechanisms are fundamen-\ntally incompatible. This framework provides the analytical structure for this survey.\nThis review is structured around this framework to synthesize three critically interconnected\nlayers:\nThe first layer encompasses theTheoretical Foundations, including core principles of au-\ntonomy and agency [38], and decision-making models like Markov Decision Processes (MDPs)\nand Partially Observable MDPs (POMDPs) [39, 40]. It is crucial to note that these", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 0}}, {"page_content": "luding core principles of au-\ntonomy and agency [38], and decision-making models like Markov Decision Processes (MDPs)\nand Partially Observable MDPs (POMDPs) [39, 40]. It is crucial to note that these models pro-\nvide a theoretical language for describing agency that originated in theSymbolic paradigm, but\nmodern systemsimplementthese concepts in entirely new ways.\nThe second layer analyzesArchitectural Frameworks, focusing on the modern infrastruc-\ntures powering theNeural paradigm. We examine systems like LangChain [41], AutoGen, and\nCrewAI, which achieve agency through mechanisms like prompt chaining, conversation orches-\ntration, and dynamic context management—a clear departure from the symbolic planning of the\nclassical lineage.\nThe third layer investigatesApplication Domains, exploring the practical deployment of\nagentic systems across fields such as healthcare [42], finance [43], scientific discovery [44], and\nlegal reasoning [45]. Our framework allows us to map these applicatio", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 1}}, {"page_content": "ng the practical deployment of\nagentic systems across fields such as healthcare [42], finance [43], scientific discovery [44], and\nlegal reasoning [45]. Our framework allows us to map these applications to the appropriate\nparadigm and analyze their unique implementation challenges.\n1.1 Current Surveys Gaps and Contributions\nThe current discourse on agentic AI suffers from the conceptual retrofitting illustrated in Fig-\nure 2. Classical AI frameworks, such as the BDI model or perceive–plan–act–reflect (PPAR)\n5", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 2}}, {"page_content": "loops, are often rhetorically applied but are fundamentally mismatched to the stochastic, non-\nsymbolic, and context-driven nature of LLM-based agents [5]. Furthermore, existing reviews\nare often narrow in scope, lacking empirical comparisons or integrated governance insights. As\nsummarized in Table 1, current literature leaves substantial gaps in understanding the field’s\ncurrent state.\nTable 1: Summary of Prior Surveys on Agentic AI\nReference Focus Key Contributions Limitations\nPlaat et al.\n(2025) [8]\nAgentic LLMs Reasoning-Acting-\nInteracting taxon-\nomy\nLimited empirical\nvalidation; no evo-\nlutionary context\nSchneider\n(2025) [46]\nGenAI to\nAgentic shift\nConceptual frame-\nwork for autonomy\nNo performance\nmetrics; ignores\narchitectural mech-\nanisms\nAcharya et al.\n(2025) [47]\nFoundational\nmethods\nCombined RL with\ncognitive architec-\ntures\nScalability not\naddressed; over-\nlooks LLM-based\nparadigms\nGridach et al.\n(2025) [44]\nScientific dis-\ncovery\nTools for au-\ntonomous research\nworkflows", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 0}}, {"page_content": "ethods\nCombined RL with\ncognitive architec-\ntures\nScalability not\naddressed; over-\nlooks LLM-based\nparadigms\nGridach et al.\n(2025) [44]\nScientific dis-\ncovery\nTools for au-\ntonomous research\nworkflows\nNo governance\ndiscussion; isolated\napplication view\nHosseini\n& Seilani\n(2025) [48]\nEnterprise strat-\negy\nAgentic design\nfor organizational\nalignment\nLack of technical\ndepth; no architec-\ntural analysis\nOzman\n(2025) [49]\nBusiness opera-\ntions\nSystematic review\nmethodology\nMissing benchmark\ncomparisons; no\nunifying frame-\nwork\nThis review directly addresses these limitations through four integrated contributions:\n1. A Novel Dual-Paradigm Taxonomy:We introduce and employ the framework in Figure 2 as\nour primary analytical tool, explicitly distinguishing symbolic and neural lineages to prevent\nconceptual retrofitting and enable accurate system classification.\n2. Architectural Clarification:We demystify the operational principles of modern neural\nframeworks (Section 4), explaining how they ach", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 1}}, {"page_content": "nceptual retrofitting and enable accurate system classification.\n2. Architectural Clarification:We demystify the operational principles of modern neural\nframeworks (Section 4), explaining how they achieve agency through mechanisms like prompt\nchaining and conversation orchestration, rather than symbolic planning.\n3. Empirical Mapping:We conduct a systematic PRISMA-based literature review of 90 stud-\nies, categorizing them using our dual-paradigm framework to trace research trends and eval-\nuate architectures by their appropriate standards.\n4. Governance Anchoring:We embed ethical, accountability, and alignment challenges within\neach paradigm of our taxonomy to ensure that safety considerations are discussed in the\ncorrect technological context (Section 7).\n6", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 2}}, {"page_content": "1.2 Structure of the Paper\nTo guide the reader through our analysis, the paper is structured to logically develop the argu-\nment for a dual-paradigm understanding of Agentic AI. We begin by establishing the necessary\ntheoretical context in Section 2, which explores the foundations of agency and introduces our\ncore taxonomic framework. Section 3 then details the systematic methodology underpinning our\nliterature review.\nThe subsequent sections apply this framework to analyze the field: Section 4 reviews key\narchitectural frameworks through our taxonomic lens, and Section 5 examines how different ap-\nplication domains influence paradigm selection. Section 6 presents a comprehensive paradigm-\naware taxonomy of the literature, serving as a foundational reference and key output of our re-\nview. Section 7 investigates the paradigm-specific nature of ethical and governance challenges,\nleading directly into Section 8, which outlines the critical research gaps identified by our analy-\nsis.\nThe ", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 0}}, {"page_content": " Section 7 investigates the paradigm-specific nature of ethical and governance challenges,\nleading directly into Section 8, which outlines the critical research gaps identified by our analy-\nsis.\nThe final sections synthesize our findings and look forward. Section 9 then charts an action-\nable research roadmap toward hybrid intelligence, building directly upon both the identified gaps\nand our stated contributions. Finally, Section 10 provides a final synthesis of our findings and\ntheir implications for the field.\nThis structure is designed to first equip the reader with the necessary conceptual tools, then\nsystematically analyze the landscape, and conclude by synthesizing the insights into a coherent\nvision for the future of Agentic AI.\n2 Theoretical Foundations: Mapping the Dual Lineages\nof Agentic Intelligence\nThe architectural history of agentic AI is not a linear progression but a branching into two dis-\ntinct paradigms, as defined by our conceptual framework (Figure 2). This secti", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 1}}, {"page_content": "of Agentic Intelligence\nThe architectural history of agentic AI is not a linear progression but a branching into two dis-\ntinct paradigms, as defined by our conceptual framework (Figure 2). This section delineates the\ntheoretical and cognitive groundwork for both theSymbolic/ClassicalandNeural/Generative\nlineages, clarifying their foundational principles and highlighting the paradigm shift that sepa-\nrates them.\n2.1 Core Principles of Autonomy and Agency\nThe conceptual language for describing agency originated within the symbolic paradigm. The\nfoundational constructs ofautonomyandagencyare essential for both lineages, though they are\nimplemented in fundamentally different ways. Autonomy refers to a system’s ability to operate\nindependently, free from direct human intervention, whereas agency encapsulates the notion of\ngoal-directed behavior that incorporates intention, contextual awareness, and decision-making\ncapabilities [50, 38]. Agentic AI synthesizes these traits by initiating tas", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 2}}, {"page_content": "cy encapsulates the notion of\ngoal-directed behavior that incorporates intention, contextual awareness, and decision-making\ncapabilities [50, 38]. Agentic AI synthesizes these traits by initiating tasks, dynamically ranking\ngoals, monitoring progress, and adjusting behavior through feedback loops [51].\nThese mechanisms parallel human executive functions such as planning, inhibition, and cog-\nnitive flexibility. They provide the high-level descriptive framework for intelligent behavior,\nwhich both symbolic and neural systems aim to achieve through divergent mechanisms.\n2.2 The Symbolic Lineage: Algorithmic Decision-Making\nThe symbolic lineage is characterized by explicit logic, algorithmic planning, and deterministic\nor probabilistic models. Its evolution provides the theoretical bedrock for pre-LLM autonomous\nsystems.\n7", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 3}}, {"page_content": "r pre-LLM autonomous\nsystems.\n7", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 4}}, {"page_content": "2.2.1 Markov Decision Processes (MDPs)\nMDPs provide the mathematical scaffolding for modeling environments with full state informa-\ntion [52, 53], a hallmark of early symbolic and classical statistical AI. An MDP is defined by\na tuple (S, A, P, R), representing states, actions, transition probabilities, and rewards. These\nsystems operate effectively in deterministic, rule-based domains but lack the capacity for robust\nreasoning under uncertainty, anchoring them firmly in the symbolic paradigm.\n2.2.2 Partially Observable MDPs (POMDPs)\nPOMDPs extend MDPs by introducing probabilisticbelief statesto handle environments where\nthe agent has incomplete information [54, 55]. This was a key advancement, allowing symbolic\nagents to infer hidden states through observation and enabling more adaptive behavior. However,\nas illustrated in Figure 3, this is still a form of algorithmic state estimation. The significant\ncomputational overhead of belief tracking limits their scalability and real-world ap", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 0}}, {"page_content": "ehavior. However,\nas illustrated in Figure 3, this is still a form of algorithmic state estimation. The significant\ncomputational overhead of belief tracking limits their scalability and real-world application [56,\n57], a fundamental constraint of the symbolic approach.\nFigure 3: Classical symbolic reasoning: Comparison between a rule-based MDP\nscheduler (left) and a belief-based POMDP assistant (right). The MDP agent relies\non explicit calendar states and deterministic policies, while the POMDP agent in-\nfers hidden user preferences from behavioral feedback. Both represent the symbolic\nparadigm’s approach to decision-making.\n2.2.3 Cognitive Architectures: BDI and SOAR\nCognitive architectures like Belief-Desire-Intention (BDI) and SOAR represent the pinnacle of\nthe symbolic paradigm’s attempt to engineer agency. They explicitly model internal states and\nprocesses, as summarized in Table 2. These systems directly implement a perceive-plan-act-\nreflect loop using symbolic representations", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 1}}, {"page_content": "mpt to engineer agency. They explicitly model internal states and\nprocesses, as summarized in Table 2. These systems directly implement a perceive-plan-act-\nreflect loop using symbolic representations, making them powerful but brittle and difficult to\nscale to complex, real-world environments. Their relationship to human cognitive functions is a\ndirect, top-down mapping of symbolic logic.\n8", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 2}}, {"page_content": "Table 2: Mapping Human Cognitive Functions to Symbolic AI Modules\nComponent Human Function Symbolic AI Parallel\nBelief ModuleWorking Memory Symbolic Knowledge Base\n/ World Model\nDesire ModuleMotivation Goal Stack / Utility Func-\ntion\nIntention ModuleExecutive Control Action Policy / Planner\nMeta-cognition LayerSelf-reflection, Error Mon-\nitoring\nMonitor / Replan Loop\n2.3 The Neural Lineage: Statistical Learning and Emergent Rea-\nsoning\nThe neural lineage is built on a foundation of statistical learning from data, culminating in the\ngenerative capabilities of large language models (LLMs). Its progression is marked by a move\naway from explicit logic toward emergent, stochastic behavior.\n2.3.1 Deep Reinforcement Learning (DRL)\nDeep Reinforcement Learning (DRL) represents a critical transition. It scales learning to high-\ndimensional inputs (like images and text) using neural networks [58, 59]. DRL agents learn poli-\ncies directly from data, moving away from hand-crafted symbolic rules. Me", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 0}}, {"page_content": ". It scales learning to high-\ndimensional inputs (like images and text) using neural networks [58, 59]. DRL agents learn poli-\ncies directly from data, moving away from hand-crafted symbolic rules. Methods such as PPO\nallow for fine-grained behavioral optimization [60, 61]. As shown in Figure 4, advancements\nlike meta-DRL introduced generalization across tasks, a precursor to the adaptability required\nfor modern agency. DRL is a bridge, using neural networks to learn the policies that symbolic\nsystems would have to be explicitly programmed with.\n2.3.2 The LLM Substrate and The Paradigm Shift\nThe emergence of Large Language Models (LLMs) was not an evolution but a revolution that\ncreated the new neural paradigm. LLMs provided a powerful, general-purpose substrate for\nreasoning based on statistical prediction in a high-dimensional space of concepts. This enabled\na fundamental architectural shift from designing cognitive agents to orchestrating generative\npipelines.\nFrameworks like LangCh", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 1}}, {"page_content": "istical prediction in a high-dimensional space of concepts. This enabled\na fundamental architectural shift from designing cognitive agents to orchestrating generative\npipelines.\nFrameworks like LangChain, AutoGen, and CrewAI do not implement symbolic PPAR loops\nor BDI architectures. They represent a new paradigm ofLLM Orchestration, where pre-trained\nmodels act as central executives that coordinate tasks through fundamentally different mecha-\nnisms, as detailed in Table 3.\nThis shift marks the definitive break from the symbolic tradition. Agency in the neural\nparadigm is an emergent property of prompt-driven orchestration, not a product of internal sym-\nbolic logic. The evolution of a personal assistant, depicted in Figure 5, culminates in this new\narchitecture.\n2.4 Multi-Agent Orchestration: The Pinnacle of the Neural Paradigm\nThe most advanced manifestation of the neural paradigm is multi-agent orchestration. Frame-\nworks like AutoGen [67] and LangGraph [81] coordinate diverse, modul", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 2}}, {"page_content": "on: The Pinnacle of the Neural Paradigm\nThe most advanced manifestation of the neural paradigm is multi-agent orchestration. Frame-\nworks like AutoGen [67] and LangGraph [81] coordinate diverse, modular agents through struc-\n9", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 3}}, {"page_content": "Figure 4: The shift toward learned behavior: Architectural contrast between vanilla\nDRL (single-task optimization) and meta-DRL (dual-loop generalization). The latter\nimproves adaptability across tasks through meta-optimization loops, moving from ex-\nplicit programming toward learned, emergent capabilities.\n10", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 0}}, {"page_content": "Figure 5: The journey from symbolic to neural agency: The evolution of a per-\nsonal assistant from a deterministic rule-based (MDP) system, to an uncertainty-aware\n(POMDP) system, and finally to a modern LLM-orchestrated agent. This journey\nbridges the two paradigms, ending with a system that exhibits intelligent behavior\nthrough entirely different mechanisms.\n11", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 0}}, {"page_content": "Table 3: Orchestration Mechanisms of Modern Neural Agentic Frameworks\nFramework Primary Mecha-\nnism\nFunctional Paradigm and Repre-\nsentative Applications\nLangChain[41,\n62, 63, 64, 65]\nPrompt Chaining Orchestrates linear sequences of\nLLM calls and API tools. Replaces\nsymbolic planning with stochastic\ngeneration of next steps. Applica-\ntions: Multi-step workflow automa-\ntions, automated medical reporting\n[66].\nAutoGen\n[67, 68]\nMulti-Agent\nConversation\nFacilitates structured dialogues be-\ntween collaborative LLM agents.\nReplaces monolithic control with\nemergent problem-solving through\nconversation. Applications: Col-\nlaborative task solving, economic\nresearch coordination [69].\nCrewAI[70, 71] Role-Based\nWorkflow\nAssigns roles and goals to a team\nof agents, managing their interac-\ntion workflow. Replaces central-\nized scheduling with dynamic, role-\ndriven process management. Ap-\nplications: Market analysis and risk\nmodeling [43].\nSemantic Kernel\n[72, 73, 74]\nPlugin/Function\nComposition\nCon", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 0}}, {"page_content": "w. Replaces central-\nized scheduling with dynamic, role-\ndriven process management. Ap-\nplications: Market analysis and risk\nmodeling [43].\nSemantic Kernel\n[72, 73, 74]\nPlugin/Function\nComposition\nConnects LLMs to pre-written code\nfunctions (\"skills\"). Replaces in-\ntegrated actuation with stochastic\nplanning of plugin sequences. Ap-\nplications: Breaking down high-\nlevel user intents into executable\nskills.\nLlamaIndex[75,\n76, 77, 78]\nRetrieval-\nAugmented\nGeneration\n(RAG)\nProvides sophisticated data connec-\ntors and indexing. Replaces internal\nsymbolic knowledge bases with on-\ndemand, external context retrieval.\nApplications: Financial sentiment\nanalysis [79], enhancing informa-\ntion retrieval for research [80].\ntured communication protocols. As visualized in Figure 6, an orchestrator (often an LLM itself)\nacts as a context manager and task router, assessing the overall goal and dynamically assigning\n12", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 1}}, {"page_content": " an LLM itself)\nacts as a context manager and task router, assessing the overall goal and dynamically assigning\n12", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 2}}, {"page_content": "specialized subtasks to other agents.\nThis architecture achieves scalability and complex problem-solving not through a single\nagent’s cognitive complexity, but through the emergent intelligence of a well-orchestrated sys-\ntem. It is the culmination of the neural lineage, firmly establishing the new orthodoxy of LLM-\ndriven pipelines and completing the paradigm shift from the symbolic AI tradition.\nFigure 6: The architecture of the neural paradigm: Multi-Agent Orchestration in mod-\nern AI systems. This schematic illustrates the operational paradigm of neural systems.\nA central orchestrator (e.g., an LLM) manages a dynamic workflow of specialized\nagents through structured messaging and context management. Functionality emerges\nfrom prompt routing and API tool use, explicitly replacing the symbolic perceive-plan-\nact-reflect loop.\n3 Methodology\nA rigorous and transparent methodology is essential for constructing a comprehensive review\nthat captures the dual paradigms of Agentic AI. This s", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 0}}, {"page_content": "mbolic perceive-plan-\nact-reflect loop.\n3 Methodology\nA rigorous and transparent methodology is essential for constructing a comprehensive review\nthat captures the dual paradigms of Agentic AI. This section outlines the systematic process\nused to identify, evaluate, and synthesize literature, with a specific focus on categorizing works\naccording to the symbolic and neural lineages defined in our conceptual framework (Figure 2).\nIt follows established review protocols to ensure reproducibility while accounting for the field’s\nrapid evolution.\n3.1 Review Design\nThis study adopts thePRISMA 2020 framework(Preferred Reporting Items for Systematic\nReviews and Meta-Analyses) [82, 83], guiding all stages from search strategy to synthesis. The\n13", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 1}}, {"page_content": "methodology is designed to capture and distinguish between the symbolic/classical and neu-\nral/generative lineages of agentic AI research across computer science, cognitive psychology,\nrobotics, and ethics.\nObjectives:This systematic review aims to provide a comprehensive analysis of agentic AI\nsystems through the following specific research objectives:\n1. To identify, classify, and synthesize literature based on the dual architectural paradigms\n(Symbolic vs. Neural) of Agentic AI.\n2. To examine the evolution of capabilities, applications, and performance metrics within\nand across each paradigm.\n3. To analyze governance frameworks and ethical challenges, contextualizing them within\ntheir respective architectural paradigms.\n4. To highlight paradigm-specific research gaps and propose informed future directions based\non the synthesized evidence.\n3.2 Data Sources and Search Strategy\nA multi-database search strategy was employed to identify literature across both historical sym-\nbolic and m", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 0}}, {"page_content": "d future directions based\non the synthesized evidence.\n3.2 Data Sources and Search Strategy\nA multi-database search strategy was employed to identify literature across both historical sym-\nbolic and modern neural agentic AI research. Sources included: IEEE Xplore, ACM Digital\nLibrary, arXiv, SpringerLink, ScienceDirect, and Google Scholar.\nThe search strategy employed a structured set of keyword clusters designed to comprehen-\nsively capture the core concepts associated with both architectural paradigms. To represent\ntheSymbolic/Classicallineage, targeted terms included foundational concepts such as \"Cog-\nnitive architectures,\" \"BDI agent,\" \"SOAR,\" \"POMDP,\" \"symbolic planning,\" and \"multi-agent\nsystems\" (in its traditional sense). Conversely, theNeural/Generativeparadigm was captured\nthrough terms reflecting its contemporary emergence, such as \"LLM agent,\" \"AI orchestration,\"\n\"prompt chaining,\" \"tool-augmented LLM,\" \"multi-agent conversation,\" and specific framework\nnames including \"Au", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 1}}, {"page_content": "gh terms reflecting its contemporary emergence, such as \"LLM agent,\" \"AI orchestration,\"\n\"prompt chaining,\" \"tool-augmented LLM,\" \"multi-agent conversation,\" and specific framework\nnames including \"AutoGen\" and \"LangChain.\" Finally, a set ofGeneralterms—\"Agentic AI,\"\n\"autonomous agent,\" and \"goal-directed AI\"—was used to ensure broad coverage and to cap-\nture literature that might bridge or transcend the paradigmatic divide. Boolean operators were\nstructured to optimize breadth and relevance (e.g., (\"autonomous agent\" OR \"agentic AI\") AND\n(\"large language model\" OR \"orchestration\" OR \"cognitive architecture\")).\nThe search scope was interdisciplinary, targeting relevant fields from computer science to\nethics. To capture the most current advancements in the rapidly evolving neural paradigm, the\nsearch included pre-print servers like arXiv, with these records being manually assessed for\nquality and relevance.\n3.3 Inclusion and Exclusion Criteria\nTo ensure the review’s methodological integ", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 2}}, {"page_content": "the\nsearch included pre-print servers like arXiv, with these records being manually assessed for\nquality and relevance.\n3.3 Inclusion and Exclusion Criteria\nTo ensure the review’s methodological integrity and thematic relevance, predefined inclusion and\nexclusion parameters were applied during the screening process. These criteria were designed to\ncapture high-quality literature from both paradigms of agentic AI.\nInclusion CriteriaThe literature search employed the following inclusion criteria to iden-\ntify publications that contribute directly to the core themes of agentic AI architectures and ap-\nplications. Specifically, we included peer-reviewed journal articles, conference proceedings, and\nformally published technical reports from recognized institutions. To capture the most recent\n14", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 3}}, {"page_content": "advancements in the rapidly evolving neural paradigm, we also incorporated high-impact pre-\nprints from arXiv, which were manually screened for methodological rigor and citation impact,\nwith a focus on those presenting novel architectures or frameworks. The scope of included work\nencompassed studies involving the design, implementation, or evaluation of autonomous agents,\nspanning both classical symbolic systems and modern LLM-orchestrated frameworks. All se-\nlected publications were required to be in English and published within the temporal window of\nJanuary 2018 to March 2025.\nExclusion CriteriaTo ensure a focused and methodologically rigorous review, studies were\nexcluded according to the following criteria. Non-English language publications were omitted.\nWe also excluded non-peer-reviewed or informal sources such as opinion pieces, editorials, blog\nposts, and unverified online content. Furthermore, studies focused exclusively on generative AI\n(e.g., for image generation or text co", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 0}}, {"page_content": "ewed or informal sources such as opinion pieces, editorials, blog\nposts, and unverified online content. Furthermore, studies focused exclusively on generative AI\n(e.g., for image generation or text completion) without incorporating agentic features like goal-\ndirectedness, tool use, or multi-step autonomy were deemed out of scope. Finally, duplicate\nrecords retrieved from multiple databases were identified and removed to prevent redundancy in\nthe analysis.\nThese criteria ensured the retention of conceptually aligned and methodologically sound\nstudies from both paradigms, preserving the review’s comprehensive scope. A summary is pro-\nvided in Table 4.\nTable 4: Inclusion and Exclusion Criteria for Literature Selection\nCategory Criteria\nInclusion\n• Peer-reviewed journal and conference papers\n• Technical reports from reputable institutions\n• Studies on autonomous agents from both symbolic and neural\nparadigms\n• Applications across various domains demonstrating agentic ca-\npabilities\n• Publ", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 1}}, {"page_content": "• Technical reports from reputable institutions\n• Studies on autonomous agents from both symbolic and neural\nparadigms\n• Applications across various domains demonstrating agentic ca-\npabilities\n• Published in English between 2018 and 2025\nExclusion\n• Non-English publications\n• Blogs, opinion pieces, or informal content\n• Studies focused solely on generative AI without agentic auton-\nomy\n• Duplicate records across multiple databases\n15", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 2}}, {"page_content": "3.4 Screening and Selection Process\nThe screening protocol adhered to the PRISMA 2020 guidelines to ensure methodological trans-\nparency and reproducibility. Records were compiled from selected databases, yielding an initial\npool of 165 items (157 from databases, 8 from supplemental sources).\nFollowing deduplication, 120 unique records remained. Title and abstract screening ex-\ncluded 42 studies due to irrelevance or insufficient focus on agentic AI. Full-text assessment\nconfirmed 78 articles met all inclusion criteria.\nIn alignment with PRISMA’s guidance for systematic reviews that require foundational con-\ntext, a supplemental phase was conducted [82]. During thematic synthesis, 12 seminal theoretical\npapers from the symbolic paradigm (e.g., foundational works on MDPs by [39] and cognitive\narchitectures by [84]) were incorporated. These papers were essential for providing complete\nhistorical context for the taxonomic framework and understanding the symbolic lineage, though\nthey were ", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 0}}, {"page_content": "ve\narchitectures by [84]) were incorporated. These papers were essential for providing complete\nhistorical context for the taxonomic framework and understanding the symbolic lineage, though\nthey were analyzed separately from contemporary neural paradigm research. This resulted in a\nfinal corpus of90 publicationsfor contextual and theoretical grounding, with 78 studies forming\nthe core for analysis of contemporary trends.\nThe process is illustrated in Figure 7, which clearly distinguishes the primary systematic\nsearch from the supplemental inclusion of foundational context.\n3.5 Data Analysis\nThe 78 studies forming the core of the review underwent thematic synthesis following the\nmethodology described by Thomas and Harden [85], with analysis specifically structured around\nthe dual-paradigm framework.\nKey Analytical Techniques:Our analysis employed a multi-faceted methodological ap-\nproach to systematically investigate the body of research. The initial phase involvedparadigm\nclassificatio", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 1}}, {"page_content": "ramework.\nKey Analytical Techniques:Our analysis employed a multi-faceted methodological ap-\nproach to systematically investigate the body of research. The initial phase involvedparadigm\nclassification, whereby each study was categorized according to its primary architectural paradigm—either\nSymbolic/Classical or Neural/Generative—based on the core operational mechanisms defined in\nour conceptual framework. Following this classification, we conducted a detailedframework\nmappingwithin each paradigm to group studies by their specific architectural approaches, in-\ncluding orchestration models (e.g., AutoGen, CrewAI), memory structures, and learning mech-\nanisms. Building on this organized foundation, across-paradigm comparisonwas performed\nto identify fundamental differences in implementation, performance, and limitations between\nthe two overarching paradigms. In parallel, we performeddomain clusteringto group appli-\ncations by sector—such as healthcare, finance, robotics, and scientific ", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 2}}, {"page_content": ", performance, and limitations between\nthe two overarching paradigms. In parallel, we performeddomain clusteringto group appli-\ncations by sector—such as healthcare, finance, robotics, and scientific discovery—which en-\nabled the identification of performance patterns and deployment strategies both within and across\nparadigms. Finally, anethical codingprocedure was applied, using a structured lexicon to tag\nrecurring themes related to governance, safety, transparency, and bias, with particular attention\npaid to how these ethical challenges manifest differently within each paradigm.\nQualitative coding was supported by tools such as NVivo [86], which enabled hierarchical\ntheme identification and cross-paradigm analysis. Quantitative results were tabulated and com-\npared within and across domains and paradigms to synthesize technical and operational insights.\nThis paradigm-informed approach ensured a nuanced understanding of the current landscape\nof Agentic AI research, supporting both th", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 3}}, {"page_content": "ains and paradigms to synthesize technical and operational insights.\nThis paradigm-informed approach ensured a nuanced understanding of the current landscape\nof Agentic AI research, supporting both theoretical grounding and real-world applicability while\nmaintaining the analytical rigor required for this review.\n16", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 4}}, {"page_content": "Figure 7: PRISMA 2020 Flow Diagram. Records were identified from databases\n(n=157) and supplemental sources (n=8). After deduplication (n=120) and title/abstract\nscreening (n=42 excluded), full-text review confirmed 78 eligible studies. A supple-\nmental phase added 12 seminal theoretical papers for contextual framing of the sym-\nbolic paradigm (shown in dashed box), yielding a final corpus of 90 publications for\nthe review.\n3.6 Limitations\nLimitationsWhile this review provides a comprehensive synthesis of Agentic AI research, sev-\neral limitations must be acknowledged. First, the inherenttemporal and scope dynamicsof the\nfield, particularly within the rapidly evolving neural paradigm, present a challenge; although our\nsearch extended to early 2025, some very recent developments may not be captured, a risk mit-\nigated but not fully eliminated by the inclusion of pre-prints. Furthermore, our methodological\napproach required acontextual reference expansionthrough the supplemental inclusio", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 0}}, {"page_content": "captured, a risk mit-\nigated but not fully eliminated by the inclusion of pre-prints. Furthermore, our methodological\napproach required acontextual reference expansionthrough the supplemental inclusion of 12\nseminal symbolic papers to ensure a robust theoretical framing of the classical lineage. We em-\nphasize that these papers, analyzed separately from contemporary research, were used strictly for\ncontextual and historical background and represent a deviation from a purely systematic retrieval\nprocess.\nAdditional constraints arose from the nature of the subject matter itself.Transparency con-\nstraintswere encountered as many state-of-the-art neural agentic systems operate as proprietary\nsolutions with limited public documentation, meaning architectural details and performance met-\n17", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 1}}, {"page_content": "rics were sometimes incomplete or inferred from secondary sources.Methodological hetero-\ngeneityacross the reviewed studies, with their varied evaluation metrics, also limited our ability\nto perform direct cross-study benchmarking, particularly between paradigms that employ funda-\nmentally different performance measures. Finally, despite implementing rigorous classification\ncriteria, theparadigm classification challengeof assigning hybrid or transitional architectures\nto a single paradigm may, in some cases, involve necessary simplification.\nThese limitations collectively highlight the challenges of conducting systematic reviews in\na nascent and fast-paced field with multiple co-existing paradigms. Our two-phase approach—a\nsystematic review of contemporary research supplemented by a narrative inclusion of founda-\ntional symbolic context—was designed to balance methodological rigor with comprehensiveness\nwhile respecting the fundamental distinctions between these architectural paradigms", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 0}}, {"page_content": "ive inclusion of founda-\ntional symbolic context—was designed to balance methodological rigor with comprehensiveness\nwhile respecting the fundamental distinctions between these architectural paradigms.\n4 Literature Review: A Dual-Paradigm Analysis\nThe rapid expansion of Agentic AI has produced a diverse yet fragmented body of research.\nThis section synthesizes the extant literature through the lens of the dual-paradigm framework\nintroduced in Figure 2, analyzing how contributions are distributed across the symbolic/classical\nand neural/generative lineages. We organize and analyze the most influential contributions across\nfoundational studies, architectural frameworks, and domain-specific applications, focusing on\ntheir operational mechanisms to clearly delineate the paradigm shift.\n4.1 Foundational Studies: The Roots of Two Lineages\nThe theoretical bedrock of Agentic AI is found in two distinct lineages, each with its own foun-\ndational breakthroughs. Landmark studies have shaped the c", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 1}}, {"page_content": "ndational Studies: The Roots of Two Lineages\nThe theoretical bedrock of Agentic AI is found in two distinct lineages, each with its own foun-\ndational breakthroughs. Landmark studies have shaped the conceptual and architectural founda-\ntions of both paradigms, spanning strategic reasoning, cognitive models, and alignment.\nThese studies collectively mark the progression from explicit, algorithmic deliberation to\nemergent, stochastic intelligence. They serve as reference points for the fundamental differences\nin how adaptability, coordination, and strategic reasoning are implemented in each paradigm,\nillustrating the conceptual divide captured by our framework.\n4.2 Architectural Paradigms: A Mechanistic Comparison\nThe advent of large language models (LLMs) has solidified the neural/generative paradigm,\nwhich operates on principles fundamentally incompatible with its symbolic predecessor. Modern\nagentic frameworks leverage LLMs as generative engines within software pipelines, explicitly\nd", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 2}}, {"page_content": "e paradigm,\nwhich operates on principles fundamentally incompatible with its symbolic predecessor. Modern\nagentic frameworks leverage LLMs as generative engines within software pipelines, explicitly\ndeparting from classical cognitive loops. Their core innovation lies in dynamic context manage-\nment, prompt engineering, and tool composition.\nThis analysis underscores that these frameworks form the backbone of the neural paradigm,\ndesigned for practical task completion through orchestration, not for simulating internal cogni-\ntive processes. Mapping them to PPAR or BDI obscures their true innovative mechanics, which\nare defined by prompt-driven stochasticity, not algorithmic symbol manipulation.\n4.3 Domain-Specific Implementations: A Paradigm-Driven Anal-\nysis\nAgentic AI frameworks are being deployed across sectors where autonomy and adaptability are\nessential. The choice of paradigm is critically influenced by domain-specific constraints—ethical,\n18", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 3}}, {"page_content": " deployed across sectors where autonomy and adaptability are\nessential. The choice of paradigm is critically influenced by domain-specific constraints—ethical,\n18", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 4}}, {"page_content": "regulatory, or epistemic. The following implementations exemplify how each paradigm is ap-\nplied.\nDomain-Specific Applications and Paradigm ChoicesThe application of Agentic AI\nreveals a distinct paradigm split influenced by the core requirements of each sector. Inhealth-\ncare, where safety and compliance are paramount, applications diverge clearly along archi-\ntectural lines. Symbolic systems, such as rule-based clinical decision support tools, are pre-\ndominantly employed for predictable and auditable tasks. In contrast, the flexibility of neural\nparadigms is leveraged for tasks like generating structured medical reports [66] and powering\non-premise edge agents [87]; however, these neural frameworks are often contained within de-\nterministic tool-chaining pipelines to ensure the reliability required in clinical settings.\nThis pattern of complementary paradigm use is also evident infinance, a domain demand-\ning high accuracy and auditability. Here, neural frameworks dominate tasks inv", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 0}}, {"page_content": "ity required in clinical settings.\nThis pattern of complementary paradigm use is also evident infinance, a domain demand-\ning high accuracy and auditability. Here, neural frameworks dominate tasks involving com-\nplex data synthesis and analysis. For instance, CrewAI’s role-based workflow is applied to mar-\nket analysis [43] as it provides a clear, auditable trail of agent actions. Similarly, LlamaIndex-\npowered models for financial sentiment [79] demonstrate how neural systems use Retrieval-\nAugmented Generation (RAG) to ground their stochastic outputs in verified data, thereby re-\nducing hallucination. Despite this, symbolic systems maintain a critical role in high-frequency\ntrading and core regulatory logic where absolute determinism is non-negotiable.\nFinally, inscientific research, which requires profound epistemic rigor, the choice of\nparadigm is dictated by the nature of the intellectual task. The deployment of AutoGen to coor-\ndinate multi-agent conversations for economic resear", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 1}}, {"page_content": "ch requires profound epistemic rigor, the choice of\nparadigm is dictated by the nature of the intellectual task. The deployment of AutoGen to coor-\ndinate multi-agent conversations for economic research [69] exemplifies the neural paradigm’s\nstrength in simulating collaborative, exploratory discovery and critique. This stands in direct\ncontrast to the role of symbolic systems, which remain the bedrock for theorem proving and log-\nical inference, highlighting a fundamental architectural choice between exploratory generation\nand deductive reasoning.\nThese implementations demonstrate that the paradigm choice is not merely technical but is\ndecisively shaped by domain-specific needs, validating the need for a clear taxonomic framework\nto classify and select appropriate architectures.\n4.4 Emerging Trends: Toward Hybrid Architectures\nThe evolution of Agentic AI is increasingly characterized by a deliberate synthesis of architec-\ntural paradigms, moving beyond isolated approaches toward integr", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 2}}, {"page_content": "ng Trends: Toward Hybrid Architectures\nThe evolution of Agentic AI is increasingly characterized by a deliberate synthesis of architec-\ntural paradigms, moving beyond isolated approaches toward integrated systems that combine\nstrengths while mitigating inherent limitations. This shift toward hybrid architectures represents\nthe field’s maturation as it seeks to balance adaptability with reliability. Importantly, these trends\nare not broad truisms about any generation of AI, but rather specific architectural responses to\nchallenges uniquely faced by large-scale, agentic systems.\nThe most significant emerging trend isneuro-symbolic integration, which aims to formally\nbridge the reliable, deterministic reasoning of symbolic systems with the adaptive, generative ca-\npabilities of neural networks [88]. This effort transcends the well-documented limitations of both\nparadigms, potentially establishing a new hybrid category that leverages their complementary\nstrengths.\nA second and particularly", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 3}}, {"page_content": "s [88]. This effort transcends the well-documented limitations of both\nparadigms, potentially establishing a new hybrid category that leverages their complementary\nstrengths.\nA second and particularly distinctive direction is the exploration ofdecentralized agent net-\nworks. Here, blockchain-based coordination mechanisms are applied to multi-agent AI systems\nto provide verifiable governance, transparent decision-making, and resilient autonomy [89]. Un-\nlike conventional centralized orchestrators, distributed consensus frameworks offer robustness\nagainst single points of failure, while also opening the possibility of economic coordination\n19", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 4}}, {"page_content": "between heterogeneous agents through tokenized incentives. This line of research directly ad-\ndresses questions of trust, accountability, and cooperative alignment—issues that become acute\nwhen scaling agentic AI across organizations or societal infrastructures.\nComplementing these architectural innovations, advances inlifelong learningframeworks\naddress a critical limitation of current LLM-based agents—their largely stateless nature [90].\nBy enabling continuous adaptation and durable knowledge retention, this trend effectively in-\njects persistent memory, a concept foundational to symbolic AI, into neural architectures. This\nsupports more context-aware, long-term, and resilient operation in dynamic environments.\nCollectively, these emerging trends signal the field’s progression from debating paradigm\nsuperiority to architecting sophisticated hybrids. Far from generic insights, they constitute tar-\ngeted responses to enduring limitations in current Agentic AI systems: brittle reasoning", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 0}}, {"page_content": "ing paradigm\nsuperiority to architecting sophisticated hybrids. Far from generic insights, they constitute tar-\ngeted responses to enduring limitations in current Agentic AI systems: brittle reasoning, cen-\ntralized governance bottlenecks, and memory deficiencies. The resulting synthesis offers the\nmost promising path toward developing Agentic AI systems that are simultaneously adaptable\nand reliable, creative and verifiable—capable of operating effectively in the complex, dynamic\nenvironments that characterize real-world applications.\n4.5 Coordination Protocols: From Algorithmic Contracts to Emer-\ngent Conversation\nA critical yet often underexplored aspect of Multi-Agent Systems (MAS) is the fundamental\ndistinction in their coordination mechanisms. A deeper examination reveals that these strategies\nare a primary differentiator between the two paradigms, reflecting their core architectural prin-\nciples:explicit algorithmsin the symbolic paradigm versusemergent, stochastically-guided\nbe", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 1}}, {"page_content": "strategies\nare a primary differentiator between the two paradigms, reflecting their core architectural prin-\nciples:explicit algorithmsin the symbolic paradigm versusemergent, stochastically-guided\nbehaviorin the neural paradigm.\nWithin theSymbolic Paradigm, coordination is achieved through pre-defined, algorithmic\nprotocols rooted in decades of distributed AI research. These protocols are engineered to ensure\npredictable, verifiable, and fault-tolerant interactions, making them indispensable for critical sys-\ntems where correctness is paramount. A quintessential example is theContract Net Protocol\n(CNP)[91], a classic negotiation framework where a manager agent announces a task through\na “call for proposals.” Other agents then evaluate their capabilities and submit bids, leading the\nmanager to award the contract to the most suitable agent. This process, analogous to an auc-\ntion, is extensively applied in domains like manufacturing and logistics scheduling. Another\nfoundational strate", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 2}}, {"page_content": "er to award the contract to the most suitable agent. This process, analogous to an auc-\ntion, is extensively applied in domains like manufacturing and logistics scheduling. Another\nfoundational strategy is theBlackboard System[92], where a shared memory space acts as a\ncentral coordination point. Specialist agents, akin to experts surrounding a physical blackboard,\nmonitor this space for relevant data and contribute their expertise incrementally to build towards\na solution. This approach is highly effective for complex, unstructured problems like medical\ndiagnosis or signal interpretation. Furthermore,Market-Based Approachesfacilitate coordi-\nnation through a virtual economy where agents buy and sell services or resources, providing a\ndecentralized method for resource allocation in networked systems.\nIn direct opposition, coordination within theNeural Paradigmis not typically governed\nby hard-coded protocols. Instead, it emerges as a property ofstructured conversation and\nprompt-driven", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 3}}, {"page_content": "ed systems.\nIn direct opposition, coordination within theNeural Paradigmis not typically governed\nby hard-coded protocols. Instead, it emerges as a property ofstructured conversation and\nprompt-driven orchestration[93, 94, 95]. Here, a central orchestrator (often an LLM itself) or\nthe agents themselves leverage their generative capabilities to dynamically assign roles, manage\ndialogue, and synthesize results. This can manifest in several distinct patterns.Conversation-\nBased Coordination[96, 97, 98], exemplified by frameworks like AutoGen, achieves collabo-\nration through structured conversational loops where agents with defined roles interact within a\ngroup chat, with the LLM’s context window managing the interaction state. A more explicit vari-\nant is theRole-Based Workflow[99] (e.g., CrewAI), where a higher-level orchestrator assigns\ntasks based on pre-defined roles and goals, though the routing decisions are still driven by LLM-\n20", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 4}}, {"page_content": "ewAI), where a higher-level orchestrator assigns\ntasks based on pre-defined roles and goals, though the routing decisions are still driven by LLM-\n20", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 5}}, {"page_content": "based reasoning rather than deterministic algorithms. Lastly,Dynamic Context Management\n[100, 81] (e.g., LangGraph) implements coordination through state machines that control infor-\nmation flow between nodes; the graph structure defines possible paths, but the specific execution\nis determined stochastically by the LLM’s output at each step.\nThe fundamental dichotomy between these coordination strategies is summarized in Table\n5, which highlights the core operational differences.\nTable 5: A Dual-Paradigm Comparison of Multi-Agent Coordination Mechanisms\nFeature Symbolic/Classical Paradigm Neural/Generative Paradigm\nPrimary Mecha-\nnism\nAlgorithmic Protocols (e.g., Contract Net,\nBlackboard)\nStructured Conversation & Prompt Or-\nchestration\nState ManagementExplicit, often centralized (e.g., Manager\nin CNP, Blackboard)\nImplicit, managed within the LLM’s con-\ntext window\nDecision ProcessDeterministic or probabilistic based on ex-\nplicit rules\nStochastic generation of next ac-\ntion/response\nF", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 0}}, {"page_content": "nager\nin CNP, Blackboard)\nImplicit, managed within the LLM’s con-\ntext window\nDecision ProcessDeterministic or probabilistic based on ex-\nplicit rules\nStochastic generation of next ac-\ntion/response\nFlexibilityLow; protocols are fixed and designed for\nanticipated scenarios\nHigh; can adapt to novel coordination pat-\nterns not explicitly programmed\nVerifiabilityHigh; the protocol’s logic can be formally\nverified and audited\nLow; the emergent coordination path is\nopaque and difficult to trace\nKey FrameworksJADE, JaCaMo, early SOAR systems AutoGen, CrewAI, LangGraph\nExampleA manager agent uses CNP to auction a\ndelivery task to the lowest-bidding drone\nagent.\nAn orchestrator LLM manages a conversa-\ntion between a programmer agent, a tester\nagent, and a writer agent to collaboratively\nbuild software.\nThis analysis confirms that the paradigm shift extends to the very fabric of multi-agent co-\nordination. The symbolic paradigm offersverifiable reliabilitythrough rigorously engineered\nprotocols", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 1}}, {"page_content": "ware.\nThis analysis confirms that the paradigm shift extends to the very fabric of multi-agent co-\nordination. The symbolic paradigm offersverifiable reliabilitythrough rigorously engineered\nprotocols, while the neural paradigm offersadaptable emergencethrough learned conversation\npatterns. This critical distinction is essential for understanding the capabilities, risks, and appro-\npriate applications of modern MAS, thereby further validating the necessity of the dual-paradigm\nframework presented in this survey.\n4.6 Evaluating Agency: Beyond Accuracy\nThe evaluation of Agentic AI systems presents a fundamental challenge that distinguishes it from\nthe assessment of traditional AI models. As the reviewer rightly notes, simple metrics like ac-\ncuracy are wholly insufficient. Measuring “agency” requires quantifying a system’s capacity for\nsustained, goal-directed behavior in dynamic environments, necessitating a multi-dimensional\nevaluation framework that accounts for paradigm-specific mech", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 2}}, {"page_content": " requires quantifying a system’s capacity for\nsustained, goal-directed behavior in dynamic environments, necessitating a multi-dimensional\nevaluation framework that accounts for paradigm-specific mechanisms of action.\nThe core challenge lies in the fact that agency is not a monolithic property but a spectrum\nencompassingautonomy,task success,efficiency, androbustness. Consequently, evaluation\nmust be tailored to the architectural paradigm.\nIn theSymbolic Paradigm, evaluation has historically focused onverifiability. Key met-\nrics includeGoal Completion Fidelity, which measures the percentage of pre-defined sub-goals\ncorrectly achieved in a plan, andPlan Optimality, which compares the cost (e.g., time, steps) of\nan agent’s generated plan against a known optimal solution. Furthermore, assessment involves\nverifyingLogical Soundnessthrough formal methods to ensure rule sets cannot derive contra-\ndictory or unsafe actions, and rigorously testingEdge Case Handlingagainst rare but critical\nsc", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 3}}, {"page_content": "ment involves\nverifyingLogical Soundnessthrough formal methods to ensure rule sets cannot derive contra-\ndictory or unsafe actions, and rigorously testingEdge Case Handlingagainst rare but critical\nscenarios either explicitly encoded in or missing from the agent’s knowledge base.\n21", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 4}}, {"page_content": "Conversely, in theNeural Paradigm, evaluation is inherently more complex due to inherent\nstochasticity. While benchmarks like AgentBench [101] and GAIA [?] represent a shift towards\nholistic assessment, they have limitations. Metrics must be designed to capture emergent capa-\nbilities and failures. This includes evaluatingLong-Horizon Task Successon complex, multi-step\ntasks (e.g., “research a topic and write a report with citations”), often measured by final outcome\nquality as judged by humans or a powerful LLM “judge.” Other critical dimensions areCon-\ntext Window and Memory Management, which assess an agent’s ability to utilize information\nacross extended interactions;Tool Use Proficiency, encompassing tool selection accuracy, call\nsequence efficiency, and error recovery;Robustness to Prompts, testing consistency across in-\nstruction rephrasings and resilience to injection attacks; and practicalCost and Latencymetrics,\nmeasuring computational expense (e.g., total tokens, API calls) ", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 0}}, {"page_content": "rompts, testing consistency across in-\nstruction rephrasings and resilience to injection attacks; and practicalCost and Latencymetrics,\nmeasuring computational expense (e.g., total tokens, API calls) and time-to-completion, which\nare crucial for real-world deployment.\nA comprehensive evaluation framework for Agentic AI must therefore integrate these di-\nmensions. It is not enough for an agent to eventually succeed at a task; it must do so efficiently,\nreliably, and in a manner that is transparent and auditable where required. This typically involves\na synergistic combination of automated metrics (e.g., success rate, number of steps), human eval-\nuation for qualitative judgment of output coherence and usefulness, and adversarial testing (e.g.,\n“red teaming”) to probe for specific failure modes like hallucination or goal divergence.\nThis paradigm-aware approach to evaluation—where symbolic systems are judged on veri-\nfiability and neural systems on robust adaptability—is essential for th", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 1}}, {"page_content": "des like hallucination or goal divergence.\nThis paradigm-aware approach to evaluation—where symbolic systems are judged on veri-\nfiability and neural systems on robust adaptability—is essential for the responsible development\nand deployment of autonomous agents. It moves the field beyond simple benchmarks towards a\nmore nuanced understanding of what it means for an AI system to be truly “agentic.”\n4.7 Summary of Insights\nSynthesizing the literature through our dual-paradigm framework reveals several fundamental\ndistinctions and clear trajectories for the field of Agentic AI. The analysis demonstrates that\nparadigm divergence is fundamental; rather than representing evolutionary stages, the sym-\nbolic and neural lineages constitute parallel development paths characterized by fundamentally\ndifferent operational mechanics—algorithmic reasoning versus stochastic orchestration. This ar-\nchitectural divergence emerges as the most critical factor in determining any agentic system’s\ninherent c", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 2}}, {"page_content": "ifferent operational mechanics—algorithmic reasoning versus stochastic orchestration. This ar-\nchitectural divergence emerges as the most critical factor in determining any agentic system’s\ninherent capabilities and limitations.\nThis division naturally leads to the principle thatmechanism determines application. The\nchoice between paradigms is far from arbitrary but is instead dictated by domain requirements.\nSymbolic architectures demonstrate particular excellence in domains demanding absolute relia-\nbility, verifiability, and safety, such as core regulatory systems and safety-critical controls. Con-\nversely, neural architectures thrive in environments requiring adaptability, sophisticated pattern\nrecognition, and operation on unstructured data, exemplified by creative research applications\nand complex customer interactions.\nLooking toward the future, the evidence indicates that thefrontier lies in hybridization.\nEmerging research trends do not suggest the ultimate victory of one para", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 3}}, {"page_content": "ns\nand complex customer interactions.\nLooking toward the future, the evidence indicates that thefrontier lies in hybridization.\nEmerging research trends do not suggest the ultimate victory of one paradigm over the other\nbut rather point toward their strategic integration. The next significant advancement will likely\nemerge from hybrid architectures that embed symbolic reasoning modules within neural orches-\ntration frameworks, effectively mitigating the weaknesses of pure neural approaches—such as\nhallucination and lack of verifiability—while preserving their adaptive strengths.\nCollectively, these insights, structured by the dual-paradigm framework, provide a cohe-\nsive and accurate narrative for understanding the field’s present state and future direction. This\napproach moves beyond a simple catalog of technologies to establish a coherent theory of archi-\ntectural design in Agentic AI, offering researchers and practitioners a principled foundation for\nsystem development and evaluatio", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 4}}, {"page_content": "mple catalog of technologies to establish a coherent theory of archi-\ntectural design in Agentic AI, offering researchers and practitioners a principled foundation for\nsystem development and evaluation.\n22", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 5}}, {"page_content": "5 Analysis of Domain-Specific Applications\nAgentic AI systems have transitioned from theoretical research to critical production deploy-\nments. This section analyzes these deployments through the lens of our dual-paradigm frame-\nwork, examining how domain-specific constraints—such as safety, regulation, and real-world\ninteraction—dictate the choice of architectural paradigm and shape implementation priorities.\nThe progression from automation to autonomy is not a function of evolutionary stage but of\nselecting the appropriate paradigm for the task’s constraints.\nTo provide a structured analysis, Table 6 maps key domains against their dominant archi-\ntectural paradigm, primary constraints, and illustrative implementations, creating a comparative\nschema based on mechanistic choice rather than chronological progression.\nThe diversity of these deployments reflects a key insight: the architectural paradigm is a\nstrategic response to domain-specific pressures. For instance, healthcare applica", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 0}}, {"page_content": " chronological progression.\nThe diversity of these deployments reflects a key insight: the architectural paradigm is a\nstrategic response to domain-specific pressures. For instance, healthcare applications heavily\nfavor symbolic or highly constrained deterministic approaches. This prioritizes safety, accu-\nracy, and auditability—a necessity in high-stakes, regulated environments—over the generative\nflexibility of pure neural systems.\nConversely, domains like education leverage the neural paradigm for its core strength: gen-\nerating adaptive, personalized, and context-aware interactions that are difficult to pre-program\nwith symbolic rules.\nFinance and Legal applications demonstrate a crucial middle ground: they are built on neural\norchestration frameworks but are heavily constrained by symbolic mechanisms (e.g., role-based\nworkflows, rigorous retrieval from verified sources) to mitigate the risks of hallucination and en-\nsure compliance. Robotics presents the most explicit hybrid model", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 1}}, {"page_content": "bolic mechanisms (e.g., role-based\nworkflows, rigorous retrieval from verified sources) to mitigate the risks of hallucination and en-\nsure compliance. Robotics presents the most explicit hybrid model, pairing symbolic systems for\nsafety-critical low-level control with neural systems for high-level coordination and adaptation.\nFurthermore, this paradigm-driven analysis reveals critical cross-domain challenges that\nmust be addressed in future research. Chief among these is the need forparadigm-specific\ngovernance frameworks. The operationalization of agentic systems requires tailored policy ap-\nproaches that account for each paradigm’s distinct risks: governing symbolic systems involves\nverifying their logical structures, while governing neural systems necessitates auditing training\ndata, prompts, and outputs for stochastic failures—a challenge further compounded in hybrid\narchitectures.\nEqually critical are the emerging challenges insecurity and resilience. As these systems\nbecome inte", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 2}}, {"page_content": "rompts, and outputs for stochastic failures—a challenge further compounded in hybrid\narchitectures.\nEqually critical are the emerging challenges insecurity and resilience. As these systems\nbecome integrated into critical infrastructure, they represent prime targets for adversarial attacks,\nthough the attack vectors differ fundamentally by paradigm. Symbolic systems face exploitation\nof logical flaws and rule manipulation, while neural systems remain vulnerable to prompt injec-\ntion, data poisoning, and other inference-time attacks that exploit their stochastic nature.\nFinally, the paradigm divide fundamentally shapeshuman-AI collaboration. Effective in-\nterface design must account for these architectural differences: interacting with symbolic sys-\ntems requires understanding their internal logic and state representations, whereas engaging with\nneural systems involves carefully steering context and interpreting often opaque, generative out-\nputs—requiring distinct approaches to oversigh", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 3}}, {"page_content": " logic and state representations, whereas engaging with\nneural systems involves carefully steering context and interpreting often opaque, generative out-\nputs—requiring distinct approaches to oversight and interpretability.\n5.1 Tool Use and Capabilities: Integration with Real-World Sys-\ntems\nA critical capability that distinguishes agentic AI from passive models is their ability to inter-\nact with and manipulate external tools and data sources via Application Programming Interfaces\n(APIs) [109, 110, 111, 112]. This functionality is the bridge between an agent’s internal rea-\nsoning and tangible action in the real world. The nature of this integration is, as our framework\npredicts, paradigm-dependent.\n23", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 4}}, {"page_content": "In theSymbolic Paradigm, tool use is typically hard-coded and deterministic. Agents call\nspecific functions with predefined parameters based on explicit logical rules. This is prevalent\nin safety-critical domains like healthcare, where agents interact with Electronic Health Record\n(EHR) systems using strict, auditable APIs (e.g., HL7 FHIR standards for reading/writing patient\ndata) or clinical decision support tools with fixed input-output schemas [113, 114].\nIn theNeural Paradigm, tool use is orchestrated and generative. Frameworks like LangChain\nand AutoGen use the LLM’s ability to understand natural language instructions to dynamically\nselect and call appropriate tools from a suite of available options. The LLM [115, 116]generates\nthe API call parameters (e.g., formulating a database query, crafting a search query) based on\nits context, which is then executed by the framework. This allows for immense flexibility but\nintroduces risks of malformed calls or unexpected outputs.\nTable 7 ", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 0}}, {"page_content": "ery, crafting a search query) based on\nits context, which is then executed by the framework. This allows for immense flexibility but\nintroduces risks of malformed calls or unexpected outputs.\nTable 7 [117, 118, 119] provides a non-exhaustive overview of the types of real-world tools\nand APIs that agentic systems are currently being integrated with, categorized by their primary\ndomain and function.\nThis integration enables agents to move beyond text generation to become truly functional\nsystems. For instance, a neural agent using AutoGen could read an email via the Outlook API,\nextract key tasks, write code to solve them using a Python tool, and then post the results to\na Slack channel—all within a single orchestrated workflow. Conversely, a symbolic agent in\na manufacturing context might reliably call a single, well-defined API to adjust a machine’s\nparameters based on its rigid internal state model.\nIn conclusion, agentic AI is not a monolithic force but a set of distinct architectura", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 1}}, {"page_content": "eliably call a single, well-defined API to adjust a machine’s\nparameters based on its rigid internal state model.\nIn conclusion, agentic AI is not a monolithic force but a set of distinct architectural paradigms.\nIts embedding into the fabric of critical systems is a story of domain-driven design, where theo-\nretical capabilities are shaped and constrained by practical, ethical, and operational realities. The\nchoice between symbolic, neural, or hybrid design is the primary engineering decision, making\nthe governance and safety challenges discussed in the next section immediate and paradigm-\nspecific imperatives.\n6 Comprehensive Taxonomy of Agentic AI Literature:\nA Paradigm-Aware Analysis\nThe accelerating pace of innovation in agentic AI necessitates a systematic organization that\nreflects its fundamental architectural schism. This section provides a paradigm-aware synthesis\nof the field, serving as the culminating evidence for our dual-lineage framework:\n• Avisual taxonomy(Figure 8) ca", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 2}}, {"page_content": "its fundamental architectural schism. This section provides a paradigm-aware synthesis\nof the field, serving as the culminating evidence for our dual-lineage framework:\n• Avisual taxonomy(Figure 8) categorizing the field’s core dimensions through the lens\nof symbolic and neural mechanisms.\n• Astructured literature map(Table 8) analyzing all 90 studies from our systematic re-\nview, now classified by their primary architectural paradigm.\n24", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 3}}, {"page_content": "Table 6: Analysis of Agentic AI Deployment Patterns by Domain and Paradigm\nDomain Dominant\nParadigm\nPrimary Constraints &\nDrivers\nRepresentative Implementation\n& Insight\nHealthcareSymbolic / De-\nterministic\nSafety, Privacy\n(HIPAA), Explain-\nability, High Reliability\nMEDITECH’s AI-infused EHR\n[102] uses deterministic, auditable\npipelines for clinical assistance,\nprioritizing predictable, rule-\nbased tool use over emergent\nneural behavior to ensure patient\nsafety and regulatory compliance.\nThis exemplifies the symbolic\nparadigm’s strength in high-\nstakes, verifiable environments.\nFinanceNeural / Or-\nchestration\nReal-time throughput,\nAuditability, Regulatory\nCompliance, Fraud\nPattern Dynamics\nMastercard Decision Intelligence\nPro[103] employs orchestrated\nneural agent swarms to analyze\ntransactions. Role-based systems\n(e.g., CrewAI) enable specialized\nagents for pattern detection and\nreporting. The focus is on scaling\ncomplex analysis, a strength of the\nneural paradigm, while layering in\ns", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 0}}, {"page_content": "tions. Role-based systems\n(e.g., CrewAI) enable specialized\nagents for pattern detection and\nreporting. The focus is on scaling\ncomplex analysis, a strength of the\nneural paradigm, while layering in\nsymbolic checks for auditability.\nRobotics &\nManufacturing\nHybrid (Sym-\nbolic + Neural)\nPhysical safety, Real-\ntime response, Embodi-\nment\nAmazon Prime Air[104] uses\nsymbolic POMDPs for reliable,\nsafe navigation under uncer-\ntainty.Siemens Smart Factories\n[105] layer neural orchestration\nframeworks over these low-level\nsymbolic planners to coordinate\nunits. This hybrid model lever-\nages the reliability of symbolism\nfor safety-critical functions and\nthe flexibility of neural systems\nfor coordination.\nEducationNeural / Con-\nversational\nPersonalization, Peda-\ngogical Efficacy, Student\nEngagement\nDuolingo Smart Bot[106] and\nCarnegie LiveHint AI[107] utilize\nfine-tuned LLMs in a single-agent\nparadigm. Their focus is on gener-\nating adaptive, context-aware in-\nteractions, a core capability of the", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 1}}, {"page_content": "uolingo Smart Bot[106] and\nCarnegie LiveHint AI[107] utilize\nfine-tuned LLMs in a single-agent\nparadigm. Their focus is on gener-\nating adaptive, context-aware in-\nteractions, a core capability of the\nneural paradigm, rather than on\ndeterministic, rule-based tutoring.\nLegal & Compli-\nance\nNeural (RAG-\nHeavy)\nPrecision, Comprehen-\nsiveness, Jurisdictional\nnuance, Hallucination\nmitigation\nJPMorgan COiN[108] andThom-\nson Reuters AI[45] rely heavily\non LlamaIndex-style retrieval to\nground contract analysis in vast le-\ngal corpora. This uses the neural\nparadigm’s strength in processing\nunstructured data but constrains\nits stochasticity with symbolic-\nlike retrieval of verified facts to\nensure accuracy.\n25", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 2}}, {"page_content": "Table 7: Examples of Real-World Tools and APIs Integrated with Agentic AI Systems\nTool/API Cat-\negory\nExample Ser-\nvices/APIs\nPrimary\nParadigm\nAgent Function & Use\nCase\nData &\nDatabase\nGoogle BigQuery,\nSnowflake, Post-\ngreSQL, Airtable API,\nApache Cassandra\nBoth (Deter-\nministic vs.\nGenerated\nqueries)\nQuerying structured data\nfor information retrieval\nand analysis (e.g., finan-\ncial records, customer\ndata).\nWeb &\nSearch\nGoogle Search API,\nSerpApi, Wikipedia\nAPI, Wolfram Alpha\nAPI, Brave Search\nAPI\nNeural Gathering real-time,\nexternal information\nto ground responses\nand overcome LLM\nknowledge cut-offs.\nSoftware &\nCloud\nGitHub API, AWS\nS3/SageMaker API,\nAzure Functions\nAPI, Google Cloud\nCompute API, Docker\nEngine API\nNeural Automating developer\nworkflows, managing\ncloud infrastructure,\nand deploying machine\nlearning models.\nBusiness &\nProductivity\nSlack API, Microsoft\nGraph (Teams, Out-\nlook), Salesforce\nREST API, Jira Cloud\nAPI, Zoom API\nNeural Automating workflows,\nsummarizing communi-", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 0}}, {"page_content": "eploying machine\nlearning models.\nBusiness &\nProductivity\nSlack API, Microsoft\nGraph (Teams, Out-\nlook), Salesforce\nREST API, Jira Cloud\nAPI, Zoom API\nNeural Automating workflows,\nsummarizing communi-\ncations, managing cus-\ntomer relationships, and\ntracking tasks.\nFinancialBloomberg Terminal\nAPI (BQL), Stripe\nAPI, Plaid API, Al-\npaca Markets API,\nReuters Eikon API\nBoth Executing trades, ana-\nlyzing market data, pro-\ncessing payments, and\nconducting risk assess-\nments.\nScientific &\nAcademic\nPubMed E-Utilities\nAPI, IEEE Xplore\nAPI, UniProt API,\nRDKit (Cheminfor-\nmatics), PyMol\nHybrid Conducting literature re-\nviews, generating hy-\npotheses, and automat-\ning steps in scientific dis-\ncovery pipelines.\nCode Execu-\ntion\nPython subpro-\ncess/REPL, Node.js\nruntime, Docker API,\nJupyter Kernel Gate-\nway API\nNeural Writing, executing, and\ndebugging code to per-\nform calculations, data\nanalysis, or solve prob-\nlems.\n26", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 1}}, {"page_content": "way API\nNeural Writing, executing, and\ndebugging code to per-\nform calculations, data\nanalysis, or solve prob-\nlems.\n26", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 2}}, {"page_content": "Figure 8: A Paradigm-Annotated Taxonomy of Agentic AI Systems. This framework organizes the field’s core components, now visually\ndifferentiated by architectural paradigm:Symbolic/Classical(blue),Neural/Generative(orange), andHybrid/General(purple). The\ntaxonomy reveals how the symbolic paradigm underpins formal decision models and cognitive architectures, while the neural paradigm\ndefines modern frameworks and orchestration patterns. Application domains are colored by their dominant paradigm, illustrating the\nstrategic choice between symbolic safety and neural adaptability. This visualization provides a clear roadmap for navigating the distinct\ndesign, governance, and implementation pathways required by each architectural lineage.\n27", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 0}}, {"page_content": "Our paradigm-aware analysis of the complete corpus reveals key patterns that were previ-\nously obscured (see Table 8):\n1.Paradigm Specialization by Domain: High-stakes, regulated domains like Healthcare\nand Legal Tech show a strong preference for symbolic or highly constrained neural archi-\ntectures (e.g., [42, 45]), while dynamic domains like Finance leverage neural orchestration\nfor complex analysis (e.g., [43]).\n2.The Governance Divide: Research in Ethics & Governance is overwhelmingly focused\non the novel challenges of the neural paradigm (e.g., [9, 120]), revealing a significant gap\nin modernized governance frameworks for purely symbolic systems.\n3.Temporal Paradigm Shift: The data shows a clear transition: symbolic and hybrid Cog-\nnitive Architectures dominated early research (2018–2021), while neural Orchestration\nFrameworks have overwhelmingly dominated post-2022, following the rise of LLMs.\n28", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 0}}, {"page_content": "021), while neural Orchestration\nFrameworks have overwhelmingly dominated post-2022, following the rise of LLMs.\n28", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 1}}, {"page_content": "Table 8: Paradigm-Based Taxonomy of Agentic AI Literature (2018–2025)\nCategory Paradigm Key Papers Year Focus Area Key Contributions\nFoundational\nTheories\nHybrid [8, 46, 47, 44, 48, 49] 2025 Autonomy frameworks Theoretical foundations bridging sym-\nbolic and neural concepts of agency\nArchitectural\nFrameworks\nNeural [67, 70, 71, 72, 73, 74, 75, 41,\n62, 63, 64, 65, 68]\n2023-\n2025\nSystem design Neural-based multi-agent orchestration,\ntool integration, and workflow manage-\nment\nHealthcare\nApplications\nSymbolic /\nHybrid\n[42, 66, 87, 121] 2023-\n2024\nMedical AI Clinical decision support using deter-\nministic and constrained neural systems\nfor safety\nRobotics &\nAutomation\nHybrid [122, 123, 105, 104, 50] 2018-\n2025\nAutonomous systems Combines symbolic planners\n(POMDPs) for safety with neural\ncomponents for adaptability\nFinancial Sys-\ntems\nNeural [124, 125, 43, 79, 108] 2023-\n2025\nFinTech Neural agents for fraud detection, algo-\nrithmic trading, and risk assessment\nEducation\nTechnology\nNeural [1", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 0}}, {"page_content": "ents for adaptability\nFinancial Sys-\ntems\nNeural [124, 125, 43, 79, 108] 2023-\n2025\nFinTech Neural agents for fraud detection, algo-\nrithmic trading, and risk assessment\nEducation\nTechnology\nNeural [106, 107] 2020-\n2025\nEdTech Neural-based adaptive learning systems\nand intelligent tutoring\nLegal & Com-\npliance\nNeural\n(RAG)\n[45] 2024 Legal tech Neural agents heavily constrained by\nsymbolic retrieval (RAG) for accuracy\nEthics & Gov-\nernance\nNeural [9, 120, 126, 127, 128, 129,\n130, 131, 132, 133, 134, 135,\n136, 137, 138, 139, 140, 141,\n142, 143, 144, 145, 146]\n2019-\n2025\nAI safety Frameworks addressing neural-specific\nchallenges (alignment, bias, opacity)\nEvaluation &\nBenchmarking\nNeural [101, 147, 148, 149, 150] 2023-\n2025\nPerformance metrics Benchmarks focused on neural agent ca-\npabilities (reasoning, tool use)\nEmerging\nTechnologies\nHybrid [151, 90, 152, 153, 154, 155,\n156, 157, 158, 159, 160, 161,\n88, 89, 162, 163, 164, 165, 166,\n167, 168, 169, 170, 171, 172,\n173]\n2020-\n2025\nInnovatio", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 1}}, {"page_content": " (reasoning, tool use)\nEmerging\nTechnologies\nHybrid [151, 90, 152, 153, 154, 155,\n156, 157, 158, 159, 160, 161,\n88, 89, 162, 163, 164, 165, 166,\n167, 168, 169, 170, 171, 172,\n173]\n2020-\n2025\nInnovation frontiers Research into neuro-symbolic integra-\ntion, quantum AI, and human-AI collab-\noration\n29", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 2}}, {"page_content": "Key Insights from the Paradigm-Aware TaxonomyOur paradigm-aware taxonomy\nyields several pivotal insights that chart the current and future state of Agentic AI. Primarily,\nit reveals a clearparadigm-market fit, wherein symbolic and hybrid architectures demonstra-\nbly dominate safety-critical applications like healthcare and robotics, while pure neural systems\nthrive in data-rich, adaptive domains such as finance and education. Furthermore, the taxon-\nomy exposes a significantgovernance imbalance; while ethical challenges within the neural\nparadigm are the subject of intense research, the governance of modern, complex symbolic sys-\ntems remains a critically underexplored area. This insight directly informs the third finding: that\nthe most viablepath forward is hybrid. The most active and promising research in emerging\ntechnologies explicitly seeks to integrate both paradigms, a strategic direction that confirms the\nthesis outlined in Section 9. Finally, the successful classification of a", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 0}}, {"page_content": "mising research in emerging\ntechnologies explicitly seeks to integrate both paradigms, a strategic direction that confirms the\nthesis outlined in Section 9. Finally, the successful classification of all 90 studies by this dualist\nframework validates its comprehensive coverage and utility as a robust tool for literature analysis\nand future research design.\n7 Ethical and Governance Challenges: A Paradigm-\nSpecific Analysis\nAs Agentic AI systems gain autonomy and are deployed in critical domains, they introduce a\ncomplex spectrum of ethical and governance concerns [120, 9, 174]. However, a critical over-\nsight in current discourse is the treatment of these challenges as monolithic. The risks and\nrequisite mitigation strategies differ profoundly between the symbolic and neural paradigms,\ndemanding a paradigm-aware approach to oversight and interdisciplinary collaboration.\nA synthesis of these issues is presented in Table 9, which expands upon standard taxonomies\nby outlining the core chall", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 1}}, {"page_content": "ding a paradigm-aware approach to oversight and interdisciplinary collaboration.\nA synthesis of these issues is presented in Table 9, which expands upon standard taxonomies\nby outlining the core challenges and, most importantly, their paradigm-specific manifestations\nand governance implications.\nAnalysis and Summary\nThe bifurcation of ethical challenges detailed in Table 9 leads to several critical and in-\nterconnected conclusions. First, it becomes evident thateffective governance cannot be ar-\nchitecturally agnostic. Regulation and ethical oversight must be predicated on the underlying\nparadigm; a requirement for \"full explainability,\" for instance, is feasible for a symbolic system\nbut may be technologically impossible for a pure neural agent, thus necessitating the develop-\nment of alternative compliance mechanisms.\nFurthermore, the rise ofhybrid systems compounds ethical complexity. An agent that\nblends paradigms inherently inherits the governance challenges of both. A neuro-symbo", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 2}}, {"page_content": "ernative compliance mechanisms.\nFurthermore, the rise ofhybrid systems compounds ethical complexity. An agent that\nblends paradigms inherently inherits the governance challenges of both. A neuro-symbolic ar-\nchitecture, for example, requires a framework capable of auditing its deterministic symbolic\nlogic while simultaneously monitoring its neural components for stochastic failures, creating a\nsignificantly more demanding oversight burden.\nConversely,the attribution gap presents a specific crisis for the neural paradigm. The\nfundamental question of \"Who is liable?\" is most acute here, as its diffuse and stochastic nature\ndirectly challenges legal frameworks built on principles of direct causation and intent. This may\nultimately require the establishment of new forms of strict liability for developers and operators.\nFinally, these distinctions mean thateffective human-AI collaboration is inherently paradigm-\ndependent. Designing appropriate human oversight requires a deep understanding ", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 3}}, {"page_content": " developers and operators.\nFinally, these distinctions mean thateffective human-AI collaboration is inherently paradigm-\ndependent. Designing appropriate human oversight requires a deep understanding of the agent’s\ncore mechanics. The process of overseeing a symbolic agent is analogous to supervising a ju-\nnior programmer—it involves checking their logical steps. In stark contrast, overseeing a neural\nagent is more akin to supervising a brilliant but unpredictable intern—it requires carefully steer-\ning their context and interpreting their often-opaque outputs.\n30", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 4}}, {"page_content": "Table 9: Paradigm-Specific Ethical and Governance Challenges in Agentic AI\nChallenge Symbolic Paradigm Mani-\nfestation\nNeural Paradigm Manifes-\ntation\nGovernance and Mitiga-\ntion Strategies\nAccountability &\nLiability[130, 131]\nFailure due to flawed logic\nor unhandled edge cases. Li-\nability is potentially trace-\nable to programmers or sys-\ntem designers.\nFailure due to stochastic out-\nputs, prompt injection, or\ntraining data biases. Liabil-\nity is diffuse and difficult to\nattribute.\nParadigm-specific stan-\ndards:Symbolic: Code\nverification, formal proof\nof correctness. Neural:\nOutput watermarking, ro-\nbust prompt shielding, audit\ntrails for context history.\nTransparency &\nExplainability\n[132, 133]\nInherently high. Reasoning\ntrace is a sequence of logical\nsteps or rule firings. \"Why?\"\nis answerable.\nInherently low. \"Reason-\ning\" is an emergent prop-\nerty of model activations.\n\"How?\" is often unanswer-\nable; \"Why?\" is inferred.\nSymbolic:Leverage native\nexplainability.Neural:\nInvest in SH", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 0}}, {"page_content": "swerable.\nInherently low. \"Reason-\ning\" is an emergent prop-\nerty of model activations.\n\"How?\" is often unanswer-\nable; \"Why?\" is inferred.\nSymbolic:Leverage native\nexplainability.Neural:\nInvest in SHAP/LIME-style\npost-hoc explanations and\nmandatory decision logs.\nHybrid:Use symbolic\nmodules to generate expla-\nnations for neural decisions.\nBias & Fairness\n[135, 136]\nBias arises from explicit,\nhand-coded rules or knowl-\nedge bases. Easier to iden-\ntify but hard to root out if\nfoundational.\nBias is latent in training data\nand amplified stochastically.\nPervasive and subtle, emerg-\ning in novel contexts.\nSymbolic:Rigorous logic\naudits, diverse design teams.\nNeural:Continuous bias\nmonitoring, curated fine-\ntuning datasets, adversarial\ndebiasing.\nSafety & Misalign-\nment[137, 138]\nRisk of \"perverse instantia-\ntion\" where agents exploit\nliteral, rigid goals with unin-\ntended consequences.\nRisk of goal drift, prompt\nhacking, and value mis-\ngeneralization where agents\npursue correlated but incor", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 1}}, {"page_content": "se instantia-\ntion\" where agents exploit\nliteral, rigid goals with unin-\ntended consequences.\nRisk of goal drift, prompt\nhacking, and value mis-\ngeneralization where agents\npursue correlated but incor-\nrect proxies.\nSymbolic:Comprehensive\nfailure mode testing.Neu-\nral:Red teaming, constitu-\ntional AI, and harmlessness\ntraining.Universal:Sand-\nboxed testing environments.\nAutonomy vs. Con-\ntrol[127, 128]\nHuman oversight is typically\ndesigned as explicit veto\npoints or permission gates\nwithin a deterministic loop.\nHuman oversight is fuzzy,\noften implemented as\n\"human-in-the-loop\" feed-\nback, which can be ignored\nor gamed by the agent.\nDefine \"meaningful\nhuman control\" by\nparadigm.Symbolic: Clear\ninterrupt signals. Neural:\nConfidence thresholding for\nautomatic deferral and nu-\nanced steering mechanisms.\nSecurity & Re-\nsilience[175, 176]\nVulnerabilities include logic\nbombs, sensor spoofing, and\nexploiting algorithmic flaws.\nVulnerabilities include\nprompt injection, train-\ning data poisoning", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 2}}, {"page_content": "echanisms.\nSecurity & Re-\nsilience[175, 176]\nVulnerabilities include logic\nbombs, sensor spoofing, and\nexploiting algorithmic flaws.\nVulnerabilities include\nprompt injection, train-\ning data poisoning, and\nadversarial attacks on em-\nbeddings.\nParadigm-specific defense:\nSymbolic: Formal verifi-\ncation, intrusion detection.\nNeural: Advanced prompt\nhardening, detection of out-\nof-distribution inputs, data\nprovenance.\n31", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 3}}, {"page_content": "Addressing the ethical and governance issues of Agentic AI is essential to harness its trans-\nformative potential. However, this analysis demonstrates that a nuanced, paradigm-specific ap-\nproach is not just beneficial but necessary. Blanket policies will inevitably fail. The path forward\nrequires technical standards, legal frameworks, and ethical guidelines that are as sophisticated\nand differentiated as the technologies they aim to govern.\nThis paradigm-specific framing, however, remains incomplete without explicit considera-\ntion of policy frameworks that account for the degrees of agency and autonomy in Agentic AI\nsystems, an issue we address next.\n7.1 Toward Agentic AI Policy\nAn overlooked but critical dimension of ethical and governance discourse is the explicit develop-\nment ofpolicy frameworks tailored to agentic AI. Current governance proposals often extend ex-\nisting AI regulations to cover autonomous systems, but they seldom distinguish between systems\nthat merely generate o", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 0}}, {"page_content": "y frameworks tailored to agentic AI. Current governance proposals often extend ex-\nisting AI regulations to cover autonomous systems, but they seldom distinguish between systems\nthat merely generate outputs and those thatexercise agency in decision-making. For agentic\nAI, the challenge lies indefining and operationalizing levels of autonomyand clarifying their\ngovernance implications.\nPolicy mechanisms must therefore incorporate criteria that distinguish different levels of\nagency. Table 10 summarizes a proposed taxonomy of agency in Agentic AI, outlining the\ncharacteristics of assistive, shared, and delegated forms of agency alongside their governance\nimplications.\nTable 10: Levels of Agency in Agentic AI and Corresponding Policy Needs\nAgency Level Characteristics Governance and Policy Requirements\nAssistiveAI provides recommendations or analysis,\nwith all final decisions made by humans.\nEnsure transparency and explainability.\nPolicies should mandate auditability of\noutputs but allow ", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 1}}, {"page_content": "quirements\nAssistiveAI provides recommendations or analysis,\nwith all final decisions made by humans.\nEnsure transparency and explainability.\nPolicies should mandate auditability of\noutputs but allow flexible use with human\noversight.\nSharedAI participates in decision-making, influ-\nencing outcomes jointly with human ac-\ntors.\nRequire clear role allocation, decision-\nlogging, and mechanisms for tracing con-\ntributions of human vs. AI actors. Liability\nis shared and must be explicitly codified.\nDelegatedAI agents operate with high autonomy, ex-\necuting decisions or actions within defined\ndomains.\nStrong accountability mechanisms, prede-\nfined bounds of autonomy, and strict liabil-\nity regimes for developers/operators. Re-\nquires robust monitoring and override ca-\npabilities.\nAccordingly, governance must move beyond paradigm-specific risk analysis toward atax-\nonomy of agency, where ethical principles and legal accountability mechanisms scale with the\ndegree of autonomy. This aligns with", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 2}}, {"page_content": "vernance must move beyond paradigm-specific risk analysis toward atax-\nonomy of agency, where ethical principles and legal accountability mechanisms scale with the\ndegree of autonomy. This aligns with calls for “meaningful human control” [127], but extends\nthem into concrete policy design that recognizes the unique governance needs of agentic AI.\n8 Research Gaps: A Paradigm-Specific Roadmap\nThe development of Agentic AI is constrained by significant, unresolved challenges. However, a\ncritical oversight in identifying these gaps is treating them as uniform across architectures. The\nresearch imperatives for symbolic systems diverge profoundly from those for neural systems,\nwith a particularly pressing need for work on hybrid architectures that can leverage the strengths\n32", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 3}}, {"page_content": "of both. As outlined in Table 11, these thematic areas require a paradigm-aware research strategy\nto ensure future systems are robust, adaptable, and aligned.\nCommentary on Key ThemesThe bifurcation of research gaps identified in Table 11 re-\nveals that the most critical overarching challenge is the current lack ofParadigm-Aware Re-\nsearch Methodologies. The tools, benchmarks, and success criteria developed for one paradigm\nfrequently prove irrelevant or misapplied to the other, creating fundamental barriers to coherent\nprogress.\nThis analysis suggests several imperative directions for future work. First, the most promis-\ning research path forward appears to lie not in pursuing either paradigm in isolation, but in their\nintentional integration. The \"Reasoning & Adaptability\" gap, for instance, represents a prime\ncandidate for neuro-symbolic solutions, wherein a neural network’s robust pattern recognition\ncapabilities are systematically guided and constrained by a symbolic reasoner’s lo", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 0}}, {"page_content": "nce, represents a prime\ncandidate for neuro-symbolic solutions, wherein a neural network’s robust pattern recognition\ncapabilities are systematically guided and constrained by a symbolic reasoner’s logical frame-\nwork.\nFurthermore, the community must movebeyond isolated benchmarksthat fail to account\nfor paradigmatic differences. There is a critical need to develop separate, rigorous evaluation\nsuites that stress-test the unique failure modes of each architecture—such as logic bombs and\nedge-case reasoning for symbolic systems, and prompt injection resilience and output stability\nfor neural systems.\nPerhaps most urgently, this bifurcation demonstrates thateffective governance cannot fol-\nlow a one-size-fits-all approach. Policymakers and ethicists must collaborate with engineers\nto develop distinct, tailored frameworks for auditing and regulating these fundamentally differ-\nent technologies. Applying the stringent verifiability standards of symbolic systems to neural\narchitectures woul", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 1}}, {"page_content": " distinct, tailored frameworks for auditing and regulating these fundamentally differ-\nent technologies. Applying the stringent verifiability standards of symbolic systems to neural\narchitectures would inadvertently stifle innovation, while applying the more flexible standards\ndesigned for neural systems to symbolic environments would overlook critical risks associated\nwith logical integrity and deterministic failure.\nConclusion\nAddressing these gaps requires a conscious departure from generic AI research. Progress\nhinges on a dual-track strategy that deepens our understanding of each paradigm’s unique chal-\nlenges while simultaneously pioneering architectures and standards for their integration. This\nparadigm-specific roadmap is essential to move from powerful but flawed prototypes to reliable\nand trustworthy agentic systems. The future of Agentic AI is not a choice between symbolism\nand connectionism, but a strategic synthesis of both.\n9 Future Directions: The Path to Hybrid Intellig", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 2}}, {"page_content": "iable\nand trustworthy agentic systems. The future of Agentic AI is not a choice between symbolism\nand connectionism, but a strategic synthesis of both.\n9 Future Directions: The Path to Hybrid Intelligence\nAgentic AI systems are rapidly evolving beyond static task automation into dynamic, collabo-\nrative, and adaptive entities [157]. Their future development will hinge on interdisciplinary ad-\nvances, technological convergence, and—critically—a paradigm-aware approach to design that\nseeks to integrate the strengths of both symbolic and neural lineages into robust hybrid architec-\ntures.\nA summary of these paradigm-aware trajectories is presented in Table 12, which outlines\nthe specific research and integration priorities for each paradigm’s evolution, moving beyond a\ngeneric technology forecast.\nAnalysis of Strategic Trajectories\nThe bifurcated future outlined in Table 12 leads to one overriding conclusion: the paramount\ndirection isArchitectural Integration. The goal is to forge a new ", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 3}}, {"page_content": "cast.\nAnalysis of Strategic Trajectories\nThe bifurcated future outlined in Table 12 leads to one overriding conclusion: the paramount\ndirection isArchitectural Integration. The goal is to forge a new class of hybrid systems that\nleverage the reliability of symbolic reasoning and the adaptability of neural generation.\n33", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 4}}, {"page_content": "Table 11: Paradigm-Specific Research Gaps and Imperatives in Agentic AI\nGap Area Symbolic Paradigm Chal-lenges Neural Paradigm Challenges Research Imperatives\nEvaluation & Bench-marks[150, 149] Lack of standardized metricsfor scalability and robustness oflogical reasoning in complex,open-world environments.\nCurrent benchmarks (e.g.,AgentBench[101],GAIA[?])fail to adequately test forsubtle misalignments, promptrobustness, and the true cost ofcontext management.\nDevelop paradigm-specificbenchmarks. Symbolic:Test logical soundness andfailure predictability. Neu-ral: Test for hallucinationunder pressure, prompt in-jection resilience, and multi-session consistency.\nReasoning & Adapt-ability[165, 166] Systems are brittle; they failcatastrophically when facedwith novel scenarios or excep-tions not covered by their rules.\nAgents struggle with true, ab-stract reasoning and value-ladenjudgment. Their \"reasoning\" isoften just sophisticated patternmatching that can break down.\nHybrid Research:In-v", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 0}}, {"page_content": "t covered by their rules.\nAgents struggle with true, ab-stract reasoning and value-ladenjudgment. Their \"reasoning\" isoften just sophisticated patternmatching that can break down.\nHybrid Research:In-vestigate neuro-symbolicarchitectures where neuralcomponents handle patternrecognition and symbolicmodules enforce rigorousreasoning and constraintchecking.\nLong-term Autonomy& Memory[90] Can maintain a persistent, sym-bolic state but struggle to learnand update their world modelfrom experience in a scalableway.\nContext window limitations cre-ate agents with severe amne-sia across sessions. Stateless-ness prevents cumulative learn-ing and building long-term rela-tionships.\nSymbolic:Research onefficient belief revision.Neural:Develop architec-tures for external, structuredmemory that agents canreliably read from and writeto.\nAI Infrastructure De-pendence[156] Performance is often con-strained by the scalability oftheorem provers and logicengines, which are sensitiveto hardware architecture. ", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 1}}, {"page_content": "eliably read from and writeto.\nAI Infrastructure De-pendence[156] Performance is often con-strained by the scalability oftheorem provers and logicengines, which are sensitiveto hardware architecture. Lessdependent on massive cloudclusters but requires special-ized, reliable compute.\nExtreme dependence on vast,expensive cloud compute fortraining and inference. Createsenvironmental costs, centralizespower, and creates vulnerabili-ties to supply chain and geopo-litical disruptions.\nDevelop energy-efficientand decentralized comput-ing paradigms. Researchmodel distillation, sparsearchitectures, and hybridcloud-edge deployment toreduce reliance on mono-lithic infrastructure.\nHuman-AI Interaction& Interface Design[158]\nInterfaces are typically explicit(e.g., config files, rule editors).The goal is to augment hu-man intelligence with transpar-ent, predictable tools. The dis-tinction between user and agentis clear.\nThe goal is often a collab-orative, conversational partner.Risk of creating opaq", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 2}}, {"page_content": "s to augment hu-man intelligence with transpar-ent, predictable tools. The dis-tinction between user and agentis clear.\nThe goal is often a collab-orative, conversational partner.Risk of creating opaque \"ora-cles\" that users over-trust. Chal-lenges in designing intuitiveinterfaces for steering, inter-rupting, and interpreting thestochastic outputs of neuralagents.\nEstablish principles forparadigm-aware HCI.Symbolic: Develop ad-vanced visualization forlogic and state. Neural: Re-search intuitive methods forcontext steering, confidencecommunication, and collab-orative task management.\nTrust & Transparency[142, 144] \"How\" decisions are made istransparent (the logic trace), but\"why\" a specific rule exists canbe opaque.\nBoth \"how\" and \"why\" areopaque. Explanations are post-hoc and often unreliable. Thisis the primary barrier to high-stakes deployment.\nSymbolic:Research onmaking goal structures andutility functions explicable.Neural:Fundamental re-search on mechanistic in-terpretability and ", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 3}}, {"page_content": "ble. Thisis the primary barrier to high-stakes deployment.\nSymbolic:Research onmaking goal structures andutility functions explicable.Neural:Fundamental re-search on mechanistic in-terpretability and generatingfaithful, real-time explana-tions.\nSafety & Alignment[137, 138] Risk of \"perverse instantiation\"– perfectly executing a flawedor oversimplified goal specifica-tion with catastrophic results.\nVulnerability to prompt injec-tion, goal drift, and value mis-generalization. Aligning astochastic model to complex hu-man values is an unsolved prob-lem.\nParadigm-specific strate-gies:Symbolic: For-mal verification of goalsand constraints. Neural:Advanced red teaming,adversarial training, and\"constitutional\" oversightmechanisms.\nInteroperability & In-tegration[167, 168]Difficult to integrate with themessy, unstructured data of thereal world and modern softwareecosystems.\nExcel at using tools via APIs butstruggle with true, semantic un-derstanding of what a tool does,leading to misuse.\nDevelo", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 4}}, {"page_content": "h themessy, unstructured data of thereal world and modern softwareecosystems.\nExcel at using tools via APIs butstruggle with true, semantic un-derstanding of what a tool does,leading to misuse.\nDevelop standards andmiddleware forparadigmbridging. Create APIsthat allow neural agents toquery symbolic reasonersfor validation and symbolicsystems to leverage neuralnetworks for perception.\nGovernance & Ac-countability[145, 146]Liability is more straightfor-ward (flawed logic can betraced) but frameworks for au-diting complex rule sets areneeded.\nA profound \"attribution gap\"exists. Legal frameworks areunprepared for harm caused byemergent, stochastic behavior.\nUrgently developparadigm-specific reg-ulatory models.Symbolic:Audit trails for decisionlogic. Neural: Mandatorycontext logging, output wa-termarking, and potentiallynew forms of developerliability.\n34", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 5}}, {"page_content": "termarking, and potentiallynew forms of developerliability.\n34", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 6}}, {"page_content": "Table 12: Paradigm-Aware Strategic Trajectories for Agentic AI\nStrategic Direction Symbolic Paradigm Evolution Neural Paradigm Evolution\nMulti-Agent Ecosys-\ntems\nDefining verifiable communi-\ncation protocols and interac-\ntion contracts for hybrid agent\nteams.\nSpecializing in emergent, role-\nbased collaboration and negotiation\n[154, 155] (e.g., CrewAI, AutoGen,\nLangGraph).\nTechnological Conver-\ngence\nProviding the reliable, verifiable\nlogic layer for cyber-physical\nsystems and smart infrastruc-\nture.\nActing as the adaptive interface\nfor integrating with IoT, robotics,\nblockchain, and quantum comput-\ning [151, 156].\nSelf-Evolving Architec-\ntures\nResearch into automated the-\norem proving and logical rule\ndiscovery for system self-\nimprovement.\nAdvancing meta-learning and\nfeedback-driven optimization\n[157] for architecture tuning and\ndeployment-aware adaptation.\nHuman-AI Collabora-\ntion\nEnabling interfaces where hu-\nmans can directly inspect, de-\nbug, and modify an agent’s log-\nical rule s", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 0}}, {"page_content": "ization\n[157] for architecture tuning and\ndeployment-aware adaptation.\nHuman-AI Collabora-\ntion\nEnabling interfaces where hu-\nmans can directly inspect, de-\nbug, and modify an agent’s log-\nical rule set and goals.\nCreating intuitive interfaces\nfor shared intent and cogni-\ntive/emotional responsiveness\n[158] via natural language.\nGovernance-First De-\nsign\nFormal verification of goal\nstructures and safety constraints\nfor embeddable governance\nmodules.\nDeveloping techniques for embed-\nded ethics, policy enforcement,\nand global accountability [9] within\nstochastic systems (e.g., IBM Gov-\nernance Stack).\nScientific DiscoveryEncoding scientific laws and\nmethodological rigor for agent-\nled hypothesis generation.\nDriving agent-led inquiry and re-\nsults analysis [159, 160] in plat-\nforms like Sakana AI Scientist\n[160] and Microsoft Discovery.\nResearch PrioritiesEstablishing benchmarks for\nlogical soundness, verifiability,\nand interoperability standards.\nEstablishing metrics for moral\nalignment,", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 1}}, {"page_content": "a AI Scientist\n[160] and Microsoft Discovery.\nResearch PrioritiesEstablishing benchmarks for\nlogical soundness, verifiability,\nand interoperability standards.\nEstablishing metrics for moral\nalignment, cognitive modeling, and\nalignment [161] (e.g., AgentBench\n[101]).\n35", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 2}}, {"page_content": "•Neuro-Symbolic Integration as the Keystone:The most profound progress will come\nfrom research that successfully couples neural networks for perception and pattern recog-\nnition with symbolic engines for reasoning and constraint checking. This is the most\npromising path to overcoming the brittleness of pure symbolism and the opacity of pure\nneural approaches.\n•Paradigm-Specialized Roles in Ecosystems:Future multi-agent ecosystems [154, 155]\nwill not be homogenous. They will consist of specialized agents—some highly neural\nfor creative tasks, some highly symbolic for regulatory compliance—that communicate\nthrough standardized protocols. The orchestration of such hybrid swarms is a critical\nresearch frontier.\n•A Dual-Track Approach to Governance:The development of safety and governance\nmechanisms [9] must continue on two tracks: advancing formal methods for symbolic\nverifiabilityanddeveloping new statistical, training-based methods for neural alignment.\nThe ultimate governance framework ", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 0}}, {"page_content": "nisms [9] must continue on two tracks: advancing formal methods for symbolic\nverifiabilityanddeveloping new statistical, training-based methods for neural alignment.\nThe ultimate governance framework for a hybrid agent will need to seamlessly combine\nboth.\n•Convergence as Amplification:The integration with other technologies [151, 156] will\namplify the capabilities of both paradigms. Neural agents will manage real-time sensor\ndata from IoT, while symbolic modules will ensure the decisions made from that data are\nsafe and compliant.\nConclusion\nThe future of Agentic AI is a synthesis. Its trajectory will be shaped not only by tech-\nnical breakthroughs but by thoughtful, paradigm-aware integration of ethics, interdisciplinary\nmethods, and infrastructure-aware governance [9]. The next conceptual turning point will be\ndefined by our ability to engineerhybrid intelligence—systems that are bothadaptableandre-\nliable, bothcreativeandsound. The question is no longer whether agents will become i", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 1}}, {"page_content": "al turning point will be\ndefined by our ability to engineerhybrid intelligence—systems that are bothadaptableandre-\nliable, bothcreativeandsound. The question is no longer whether agents will become intelligent\npartners, but whether we can architect a future of hybrid intelligence that is both powerful and\ntrustworthy.\n10 Conclusion\nAgentic AI represents a fundamental paradigm shift in the design of intelligent systems, but its\nrapid evolution has led to a fragmented and often anachronistic understanding of the field. This\nreview has addressed this confusion by introducing and validating a novel conceptual frame-\nwork: the existence of two distinct lineages of Agentic AI—theSymbolic/Classicaland the\nNeural/Generative—each with fundamentally different operational mechanics, strengths, and\nlimitations.\nOur analysis demonstrates that the common practice ofconceptual retrofitting—describing\nmodern LLM-orchestrated agents with the language of symbolic systems (e.g., PPAR loops,\nBDI)—obscure", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 2}}, {"page_content": "imitations.\nOur analysis demonstrates that the common practice ofconceptual retrofitting—describing\nmodern LLM-orchestrated agents with the language of symbolic systems (e.g., PPAR loops,\nBDI)—obscures their true nature and impedes progress. Through a systematic, paradigm-aware\nreview of the literature, we have established three central tenets. First,the architectural di-\nvide is both real and meaningful; symbolic systems excel in environments requiring safety,\nverifiability, and explicit logic (e.g., healthcare, robotics control), while neural systems thrive\nin domains requiring adaptability, pattern recognition, and operation on unstructured data (e.g.,\nfinance, creative research) (Sections 5, 6).\nFurthermore, this divide dictates thatgovernance must be paradigm-specific. The ethical\nchallenges and requisite mitigation strategies differ profoundly between paradigms, meaning\naccountability for a symbolic system involves auditing its logic, whereas for a neural system, it\n36", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 3}}, {"page_content": "llenges and requisite mitigation strategies differ profoundly between paradigms, meaning\naccountability for a symbolic system involves auditing its logic, whereas for a neural system, it\n36", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 4}}, {"page_content": "necessitates auditing its training data and prompts. This renders a one-size-fits-all approach to\nAI ethics fundamentally insufficient (Section 7).\nCritically, our findings indicate thatthe most productive path forward is hybrid, not iso-\nlated. The most pressing research gaps and promising future directions lie not in the isolated\nimprovement of either paradigm, but in their strategic integration into neuro-symbolic architec-\ntures that leverage the complementary strengths of symbolic reliability and neural adaptability\n(Sections 8, 9).\nThis dual-paradigm framework provides the essential analytical lens to move the field be-\nyond a simple catalog of technologies toward a coherent theory of architectural design in Agentic\nAI. It offers researchers, engineers, and policymakers a precise vocabulary and a functional tax-\nonomy to classify systems, evaluate their capabilities and risks appropriately, and make informed\ndesign choices.\nUltimately, the development of Agentic AI is not merely ", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 0}}, {"page_content": "abulary and a functional tax-\nonomy to classify systems, evaluate their capabilities and risks appropriately, and make informed\ndesign choices.\nUltimately, the development of Agentic AI is not merely a technical challenge—it is a so-\nciotechnical one. Its success will depend on whether we can architect systems that are not only\npowerful but also trustworthy. This requires a conscious and deliberate effort to build hybrid\nintelligence—systems that are both adaptable and reliable, both creative and sound. By recog-\nnizing and embracing the distinct nature of these two architectural lineages, we can steer this\ntransformative technology toward a future where agentic systems truly serve as trusted collabo-\nrators in scientific discovery (understanding), in providing fair and accessible services (equity),\nand in forming the robust, verifiable backbone of critical infrastructure (resilience).\nReferences\n[1] Christopher Wissuchek and Patrick Zschech. Exploring agentic artificial intelligence s", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 1}}, {"page_content": " (equity),\nand in forming the robust, verifiable backbone of critical infrastructure (resilience).\nReferences\n[1] Christopher Wissuchek and Patrick Zschech. Exploring agentic artificial intelligence sys-\ntems: Towards a typological framework.arXiv preprint arXiv:2508.00844, July 2025.\n[2] Panneer Selvam Viswanathan. Agentic ai: A comprehensive framework for autonomous\ndecision-making systems in artificial intelligence.International Journal of Computer En-\ngineering and Technology, 16(1):862–880, 2025. IJCET, ISSN Print: 0976-6367; Online:\n0976-6375.\n[3] J. Xie, Z. Chen, R. Zhang, X. Wan, and G. Li. Large multimodal agents: A survey.arXiv\n[cs.CV], 2024.\n[4] H. Du, S. Thudumu, R. Vasa, and K. Mouzakis. A survey on context-aware multi-agent\nsystems: Techniques, challenges and future directions.arXiv [cs.MA], 2025.\n[5] B. Archibald, M. Calder, M. Sevegnani, and M. Xu. Quantitative modelling and analysis\nof bdi agents.Softw. Syst. Model., 23(2):343–367, 2024.\n[6] Q. Zeng et al. Perceive, re", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 2}}, {"page_content": "s.arXiv [cs.MA], 2025.\n[5] B. Archibald, M. Calder, M. Sevegnani, and M. Xu. Quantitative modelling and analysis\nof bdi agents.Softw. Syst. Model., 23(2):343–367, 2024.\n[6] Q. Zeng et al. Perceive, reflect, and plan: Designing llm agent for goal-directed city\nnavigation without instructions.arXiv [cs.AI], 2024.\n[7] L. E. Erdogan et al. Plan-and-act: Improving planning of agents for long-horizon tasks.\narXiv [cs.CL], 2025.\n[8] A. Plaat, M. van Duijn, N. van Stein, M. Preuss, P. van der Putten, and K. J. Batenburg.\nAgentic large language models, a survey.arXiv [cs.AI], 2025.\n[9] G.A. Gabison and R.P. Xian. Inherent and emergent liability issues in llm-based agentic\nsystems: a principal-agent perspective.arXiv [cs.CY], 2025.\n[10] Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan\nChen, Jiakai Tang, Xu Chen, Yankai Lin, Wayne Xin Zhao, Zhewei Wei, and Jirong Wen.\nA survey on large language model based autonomous agents.Front. Comput. Sci., 18(6),\n2024.\n37", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 3}}, {"page_content": "Zhang, Zhiyuan\nChen, Jiakai Tang, Xu Chen, Yankai Lin, Wayne Xin Zhao, Zhewei Wei, and Jirong Wen.\nA survey on large language model based autonomous agents.Front. Comput. Sci., 18(6),\n2024.\n37", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 4}}, {"page_content": "[11] Pengyu Zhao, Zijian Jin, and Ning Cheng. An in-depth survey of large language model-\nbased artificial intelligence agents. 2023.\n[12] Shuaihang Chen, Yuanxing Liu, Wei Han, Weinan Zhang, and Ting Liu. A survey on\nLLM-based multi-agent system: Recent advances and new frontiers in application. 2024.\n[13] B. Liang. Ai reasoning in deep learning era: From symbolic ai to ...Mathematics,\n13(11):1707, 2025. Includes section “Symbolic Reasoning Era (1950s–1980s)”.\n[14] William R. Swartout. Rule-based expert systems: The mycin experiments of the stan-\nford heuristic programming project: B.g. buchanan and e.h. shortliffe, (addison-wesley,\nreading, ma, 1984); 702 pages, $40.50.Artificial Intelligence, 26(3):364–366, 1985.\n[15] R. N. Thomas and R. Gupta. A survey on machine learning approaches and its tech-\nniques. In2020 IEEE International Students’ Conference on Electrical, Electronics and\nComputer Science (SCEECS), pages 1–6, 2020.\n[16] T. Nithya, V . Nivas Kumar, Gayathri, S. Deepa, V . C", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 0}}, {"page_content": "d its tech-\nniques. In2020 IEEE International Students’ Conference on Electrical, Electronics and\nComputer Science (SCEECS), pages 1–6, 2020.\n[16] T. Nithya, V . Nivas Kumar, Gayathri, S. Deepa, V . C, and R. Siva Subramanian. A com-\nprehensive survey of machine learning: Advancements, applications, and challenges. In\n2023 Second International Conference on Augmented Intelligence and Sustainable Sys-\ntems (ICAISS), pages 354–361, 2023.\n[17] Maria Trigka and Elias Dritsas. A comprehensive survey of machine learning techniques\nand models for object detection.Sensors, 25(1):214, 2025.\n[18] William G. Hatcher and Wei Yu. A survey of deep learning: Platforms, applications and\nemerging research trends.IEEE Access, 6:24411–24432, 2018.\n[19] Md Zahangir Alom, Tarek M. Taha, Christopher Yakopcic, Stefan Westberg, Paheding\nSidike, Mst Shamima Nasrin, Brian C. Van Esesn, Abdul A. S. Awwal, and Vijayan K.\nAsari. A state-of-the-art survey on deep learning theory and architectures.Electronics,\n8(3):", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 1}}, {"page_content": "tefan Westberg, Paheding\nSidike, Mst Shamima Nasrin, Brian C. Van Esesn, Abdul A. S. Awwal, and Vijayan K.\nAsari. A state-of-the-art survey on deep learning theory and architectures.Electronics,\n8(3):292, 2019.\n[20] Shengli Dong, Peilin Wang, and Ke Chen Abbas. A survey on deep learning and its\napplications.Computer Science Review, 40:100379, 2021.\n[21] Talaei Khoei, H. Ould Slimane, and N. Kaabouch. Deep learning: Systematic review,\nmodels, challenges, and research directions.Neural Computing and Applications, 2023.\n[22] Pooja Chhabra and D. S. Goyal. A thorough review on deep learning neural network.\nIn2023 International Conference on Artificial Intelligence and Smart Communication\n(AISC), pages 220–226, 2023.\n[23] T. Sakirin and S. Kusuma. A survey of generative artificial intelligence techniques.Baby-\nlonian Journal of Artificial Intelligence, 2023:10–14, 2023.\n[24] G. Anandhi. A comprehensive survey on generative ai techniques and their tools: Re-\ncent advances, applications, oppo", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 2}}, {"page_content": "techniques.Baby-\nlonian Journal of Artificial Intelligence, 2023:10–14, 2023.\n[24] G. Anandhi. A comprehensive survey on generative ai techniques and their tools: Re-\ncent advances, applications, opportunities, and challenges.Recent Research in Machine\nLearning and Cloud Computing, 4(1):44–54, 2025.\n[25] S. S. Sengar, A. B. Hasan, S. Kumar, and F. Carroll. Generative artificial intelligence: A\nsystematic review and applications.Multimedia Tools and Applications, 84(21):23661–\n23700, 2024.\n[26] F. P. S. Surbakti. Systematic Literature Review on generative AI: Ethical challenges and\nopportunities.International Journal of Advanced Computer Science and Applications,\n16(5), 2025.\n[27] Zheng Zhang, Jie Zhang, Xiang Zhang, and Wei Mai. A comprehensive overview\nof Generative AI (GAI): Technologies, applications, and challenges.Neurocomputing,\n632:129645, 2025.\n38", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 3}}, {"page_content": ", applications, and challenges.Neurocomputing,\n632:129645, 2025.\n38", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 4}}, {"page_content": "[28] Z. Durante et al. Agent AI: Surveying the horizons of multimodal interaction. arXiv\npreprint arXiv:2401.03568, 2024.\n[29] T. Masterman, S. Besen, M. Sawtell, and A. Chao. The landscape of emerging AI\nagent architectures for reasoning, planning, and tool calling: A survey. arXiv preprint\narXiv:2404.11584, 2024.\n[30] Francesco Piccialli, D. Chiaro, S. Sarwar, D. Cerciello, P. Qi, and V . Mele. AgentAI: A\ncomprehensive survey on autonomous agents in distributed AI for industry 4.0.Expert\nSystems with Applications, 291:128404, 2025.\n[31] D. B. Acharya, K. Kuppan, and B. Divya. Agentic AI: Autonomous intelligence for\ncomplex goals—A comprehensive survey.IEEE Access, 13:18912–18936, 2025.\n[32] P. S. Viswanathan. Agentic ai: A comprehensive framework for autonomous decision-\nmaking systems in artificial intelligence.International Journal of Computer Engineering\nand Technology, 16(1):862–879, 2025.\n[33] Aske Plaat, Max van Duijn, Nathan van Stein, Mike Preuss, Peter van der Putten, and\nKe", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 0}}, {"page_content": "n artificial intelligence.International Journal of Computer Engineering\nand Technology, 16(1):862–879, 2025.\n[33] Aske Plaat, Max van Duijn, Nathan van Stein, Mike Preuss, Peter van der Putten, and\nKees Joost Batenburg. Agentic large language models, a survey.arXiv, 2025.\n[34] Johannes Schneider. Generative to agentic ai: Survey, conceptualization, and challenges.\narXiv, 2025.\n[35] Saeid Hosseini and Hamed Seilani. The role of agentic ai in shaping a smart future: A\nsystematic review.Array, 26:100399, 2025.\n[36] Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian\nMin, Beichen Zhang, Junjie Zhang, Zican Dong, Yifan Du, Chen Yang, Yushuo Chen,\nZhipeng Chen, Jinhao Jiang, Ruiyang Ren, Yifan Li, Xinyu Tang, Zikang Liu, Peiyu Liu,\nJian-Yun Nie, and Ji-Rong Wen. A survey of large language models.arXiv preprint\narXiv:2303.18223, 2023.\n[37] Zhongwei Wan, Xin Wang, Che Liu, Samiul Alam, Yu Zheng, Jiachen Liu, Zhongnan Qu,\nShen Yan, Yi Zhu, Quanlu Zhang, Mosharaf ", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 1}}, {"page_content": " survey of large language models.arXiv preprint\narXiv:2303.18223, 2023.\n[37] Zhongwei Wan, Xin Wang, Che Liu, Samiul Alam, Yu Zheng, Jiachen Liu, Zhongnan Qu,\nShen Yan, Yi Zhu, Quanlu Zhang, Mosharaf Chowdhury, and Mi Zhang. Efficient large\nlanguage models: A survey.Transactions on Machine Learning Research (TMLR), 2024.\nPublished May 20, 2024; accepted Sept 17, 2024.\n[38] N. Kolt. Governing ai agents.arXiv [cs.AI], 2025.\n[39] L. P. Kaelbling, M. L. Littman, and A. R. Cassandra. Planning and acting in partially\nobservable stochastic domains.Artificial Intelligence, 101(1–2):99–134, 1998. [Online]\nAvailable:.\n[40] Iadine Chadès, Luz V Pascal, Sam Nicol, Cameron S Fletcher, and Jonathan Ferrer-\nMestres. A primer on partially observable markov decision processes (pomdps).Methods\nEcol. Evol., 12(11):2058–2072, 2021. [Online] Available:.\n[41] V . Mavroudis. Langchain v0.3.Preprints Organization, 2024.\n[42] A. Singh, A. Ehtesham, S. Mahmud, and J.-H. Kim. Revolutionizing mental health care\nt", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 2}}, {"page_content": "12(11):2058–2072, 2021. [Online] Available:.\n[41] V . Mavroudis. Langchain v0.3.Preprints Organization, 2024.\n[42] A. Singh, A. Ehtesham, S. Mahmud, and J.-H. Kim. Revolutionizing mental health care\nthrough langchain: A journey with a large language model. In2024 IEEE 14th Annual\nComputing and Communication Workshop and Conference (CCWC), pages 0073–0078,\n2024.\n[43] G. Chandrashekar, M.T. Akram, M. Khan, P. Kumar, and P. Mandal. A survey on stock\ninvestment risk analysis using crewai multi-agent system.International Research Journal\nof Modernization in Engineering Technology and Science, 7(1):5647–5650, 2025.\n[44] M. Gridach, J. Nanavati, K. Z. E. Abidine, L. Mendes, and C. Mack. Agentic ai for sci-\nentific discovery: A survey of progress, challenges, and future directions.arXiv [cs.CL],\n2025.\n39", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 3}}, {"page_content": "025.\n39", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 4}}, {"page_content": "[45] V . Magesh, F. Surani, M. Dahl, M. Suzgun, C.D. Manning, and D.E. Ho. Hallucination-\nfree? assessing the reliability of leading ai legal research tools.arXiv [cs.CL], 2024.\n[46] J. Schneider. Generative to agentic ai: Survey, conceptualization, and challenges.arXiv\n[cs.AI], 2025.\n[47] D. B. Acharya, K. Kuppan, and B. Divya. Agentic ai: Autonomous intelligence for\ncomplex goals—a comprehensive survey.IEEE Access, 13:18912–18936, 2025.\n[48] S. Hosseini and H. Seilani. The role of agentic ai in shaping a smart future: A systematic\nreview.Array (N. Y.), 26(100399):100399, 2025.\n[49] R. Sapkota, K. I. Roumeliotis, and M. Karkee. Ai agents vs. agentic ai: A conceptual\ntaxonomy, applications and challenges.arXiv [cs.AI], 2025.\n[50] V . Patel, S. Kanani, T. Pathak, P. Patel, M. I. Ali, and J. Breslin. A demonstration of smart\ndoorbell design using federated deep learning.arXiv [cs.DC], 2020.\n[51] V . Trencsenyi, A. Mensfelt, and K. Stathis. The influence of human-inspired agentic\nsophisti", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 0}}, {"page_content": " Breslin. A demonstration of smart\ndoorbell design using federated deep learning.arXiv [cs.DC], 2020.\n[51] V . Trencsenyi, A. Mensfelt, and K. Stathis. The influence of human-inspired agentic\nsophistication in llm-driven strategic reasoners.arXiv [cs.AI], 2025.\n[52] Y . Lu, M. S. Squillante, and C. W. Wu. A general markov decision process framework for\ndirectly learning optimal control policies.arXiv [cs.LG], 2019.\n[53] Y . Lu, M. S. Squillante, and C. W. Wu. Markov decision process framework for control-\nbased reinforcement learning.ACM SIGMETRICS Performance Evaluation Review,\n51(2):39–41, 2023.\n[54] B. Rozek, J. Lee, H. Kokel, M. Katz, and S. Sohrabi. Partially observable hierarchical\nreinforcement learning with ai planning (student abstract).Proc. Conf. AAAI Artif. Intell.,\n38(21):23635–23636, 2024.\n[55] C. Lu, R. Shi, Y . Liu, K. Hu, S. S. Du, and H. Xu. Rethinking transformers in solving\npomdps.arXiv [cs.LG], 2024.\n[56] L. Frering, G. Steinbauer-Wagner, and A. Holzinger. Integrat", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 1}}, {"page_content": "5–23636, 2024.\n[55] C. Lu, R. Shi, Y . Liu, K. Hu, S. S. Du, and H. Xu. Rethinking transformers in solving\npomdps.arXiv [cs.LG], 2024.\n[56] L. Frering, G. Steinbauer-Wagner, and A. Holzinger. Integrating belief-desire-intention\nagents with large language models for reliable human–robot interaction and explainable\nartificial intelligence.Eng. Appl. Artif. Intell., 141(109771):109771, 2025.\n[57] S. Gillen and K. Byl. Explicitly encouraging low fractional dimensional trajectories via\nreinforcement learning.arXiv [cs.LG], 2020.\n[58] J. Singh, Raghav Magazine, Y . Pandya, and A. Nambi. Agentic reasoning and tool inte-\ngration for llms via reinforcement learning.arXiv [cs.AI], 2025.\n[59] A. Varun Bodepudi, N. Katnapally, V . Velaga, C. S. Moore, P. C. R. Chinta, and L. M.\nKaraka. Agentic ai and reinforcement learning: Towards more autonomous and adaptive\nai systems.Journal for Educators, Teachers and Trainers, 11(1):177–193, 2020.\n[60] J. Kumar and V . K. Elumalai. A proximal policy optimiza", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 2}}, {"page_content": "reinforcement learning: Towards more autonomous and adaptive\nai systems.Journal for Educators, Teachers and Trainers, 11(1):177–193, 2020.\n[60] J. Kumar and V . K. Elumalai. A proximal policy optimization based deep reinforcement\nlearning framework for tracking control of a flexible robotic manipulator.Results Eng.,\n25(104178):104178, 2025.\n[61] I. N. Yazid and E. Rachmawati. Autonomous driving system using proximal policy op-\ntimization in deep reinforcement learning.IAES Int. J. Artif. Intell. (IJ-AI), 12(1):422,\n2023.\n[62] R. Johnson.LangChain Essentials: From Basics to Advanced AI Applications. HiTeX\nPress, 2025.\n[63] M. Gupta.LangChain in your Pocket: LangChain Essentials: From Basic Concepts to\nAdvanced Applications. Packt Publishing, Birmingham, England, 2024.\n40", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 3}}, {"page_content": "[64] O. Topsakal and T.C. Akinci. Creating large language model applications utilizing\nlangchain: A primer on developing llm apps fast. InInternational Conference on Ap-\nplied Engineering and Natural Sciences, volume 1, pages 1050–1056, 2023.\n[65] T. Taulli and G. Deshmukh.Building generative AI agents: Using LangGraph, AutoGen,\nand CrewAI. APress, Berlin, Germany, 2025.\n[66] J. Huh, H.J. Park, and J.C. Ye. Breast ultrasound report generation using langchain.arXiv\n[eess.IV], 2023.\n[67] Q. Wu et al. Autogen: Enabling next-gen llm applications via multi-agent conversation.\narXiv [cs.AI], 2023.\n[68] V . Dibia.Multi-Agent Systems with AutoGen. Manning Publications, New York, NY ,\n2025.\n[69] H. Dawid, P. Harting, H. Wang, Z. Wang, and J. Yi. Agentic workflows for economic\nresearch: Design and implementation.arXiv [econ.GN], 2025.\n[70] P. Venkadesh, S. V . Divya, and K. S. Kumar. Unlocking ai creativity: A multi-agent\napproach with crewai.Journal of Trends in Computer Science and Smart Techn", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 0}}, {"page_content": "mplementation.arXiv [econ.GN], 2025.\n[70] P. Venkadesh, S. V . Divya, and K. S. Kumar. Unlocking ai creativity: A multi-agent\napproach with crewai.Journal of Trends in Computer Science and Smart Technology,\n6(4):338–356, 2024.\n[71] Z. Duan and J. Wang. Exploration of llm multi-agent application implementation based\non langgraph+crewai.arXiv [cs.MA], 2024.\n[72] M. Kothapalli. Integrating web applications with azure openai services: A focus on se-\nmantic kernel.Int. J. Sci. Res. (Raipur), 13(3):1918–1923, 2024.\n[73] L.A. Meyer.Building AI Applications with Microsoft Semantic Kernel: Easily integrate\ngenerative AI capabilities and copilot experiences into your applications. Packt Publish-\ning, Birmingham, England, 2024.\n[74] D. Costea.Microsoft Semantic Kernel in Action. Manning Publications, Shelton, Con-\nnecticut, USA, 2025.\n[75] A. Gheorghiu.Building Data-Driven Applications with LlamaIndex: A practical guide to\nretrieval-augmented generation (RAG) to enhance LLM applications. Packt Pu", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 1}}, {"page_content": " Shelton, Con-\nnecticut, USA, 2025.\n[75] A. Gheorghiu.Building Data-Driven Applications with LlamaIndex: A practical guide to\nretrieval-augmented generation (RAG) to enhance LLM applications. Packt Publishing,\nBirmingham, England, 2024.\n[76] J. Ramirez-Medina, M. Ataei, and A. Amirfazli. Accelerating scientific research through\na multi-llm framework.arXiv [physics.app-ph], 2025.\n[77] D. Mozolevskyi and W. AlShikh. Comparative analysis of retrieval systems in the real\nworld.arXiv [cs.IR], 2024.\n[78] N. Braunschweiler, R. Doddipatla, S. Keizer, and S. Stoyanchev. Evaluating large lan-\nguage models for document-grounded response generation in information-seeking dia-\nlogues.arXiv [cs.CL], 2023.\n[79] T. Konstantinidis, G. Iacovides, M. Xu, T.G. Constantinides, and D. Mandic. Finllama:\nFinancial sentiment classification for algorithmic trading applications.arXiv [cs.CL],\n2024.\n[80] V .K. Kommineni, B. König-Ries, and S. Samuel. Harnessing multiple llms for informa-\ntion retrieval: A case st", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 2}}, {"page_content": "l sentiment classification for algorithmic trading applications.arXiv [cs.CL],\n2024.\n[80] V .K. Kommineni, B. König-Ries, and S. Samuel. Harnessing multiple llms for informa-\ntion retrieval: A case study on deep learning methodologies in biodiversity publications.\narXiv [cs.IR], 2024.\n[81] J. Wang and Z. Duan. Agent ai with langgraph: A modular framework for enhancing\nmachine translation using large language models.arXiv [cs.CL], 2024.\n41", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 3}}, {"page_content": "[82] M.J. Page et al. The prisma 2020 statement: an updated guideline for reporting systematic\nreviews.BMJ, 372:n71, 2021.\n[83] M.J. Page et al. Prisma 2020 explanation and elaboration: updated guidance and exem-\nplars for reporting systematic reviews.BMJ, 372:n160, 2021.\n[84] J. E. Laird. An analysis and comparison of act-r and soar.arXiv [cs.AI], 2022.\n[85] J. Thomas and A. Harden. Methods for the thematic synthesis of qualitative research in\nsystematic reviews.BMC Med. Res. Methodol., 8(1):45, 2008.\n[86] T.T. Van, H.D. The, T.V . Van, and M.D. Van. Applying qualitative research in manage-\nment studies - theory and practical experiences: Using nvivo 15.ijirss, 8(2):4617–4626,\n2025.\n[87] A. Basit, K. Hussain, M.A. Hanif, and M. Shafique. Medaide: Leveraging large language\nmodels for on-premise medical assistance on edge devices.arXiv [cs.AI], 2024.\n[88] B.S. Nayak. Neuro-symbolic integration in ai agents: Bridging the gap between per-\nception and reasoning.International Journal of Com", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 0}}, {"page_content": "emise medical assistance on edge devices.arXiv [cs.AI], 2024.\n[88] B.S. Nayak. Neuro-symbolic integration in ai agents: Bridging the gap between per-\nception and reasoning.International Journal of Computer Engineering and Technology,\n16(1):1142–1158, 2025.\n[89] M.M. Karim, D.H. Van, S. Khan, Q. Qu, and Y . Kholodov. Ai agents meet blockchain: A\nsurvey on secure and scalable collaboration for multi-agents.Future Internet, 17(2):57,\n2025.\n[90] J. Zheng et al. Lifelong learning of large language model based agents: A roadmap.arXiv\n[cs.AI], 2025.\n[91] Lai Xu and Hans Weigand. The evolution of the contract net protocol. In X. Sean Wang,\nGe Yu, and Hongjun Lu, editors,Advances in Web-Age Information Management, pages\n257–264, Berlin, Heidelberg, 2001. Springer Berlin Heidelberg.\n[92] I D Craig. Blackboard systems.Artif. Intell. Rev., 2(2):103–118, 1988.\n[93] Uwe M. Borghoff, Paolo Bottoni, and Remo Pareschi. Human-artificial interaction in the\nage of agentic ai: a system-theoretical approach", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 1}}, {"page_content": "Blackboard systems.Artif. Intell. Rev., 2(2):103–118, 1988.\n[93] Uwe M. Borghoff, Paolo Bottoni, and Remo Pareschi. Human-artificial interaction in the\nage of agentic ai: a system-theoretical approach.Frontiers in Human Dynamics, 7, May\n2025.\n[94] Zhao Wang, Sota Moriyama, Wei-Yao Wang, Briti Gangopadhyay, and Shingo Taka-\nmatsu. Talk structurally, act hierarchically: A collaborative framework for llm multi-agent\nsystems, 2025.\n[95] Dimitrios Brodimas, Alexios Birbas, Dimitrios Kapolos, and Spyros Denazis. Intent-\nbased infrastructure and service orchestration using agentic-AI.IEEE Open J. Commun.\nSoc., pages 1–1, 2025.\n[96] Alex Casella and Wayne Wang. Performant llm agentic framework for conversational ai,\n2025.\n[97] Ziren Luo, Di Li, Jiafu Wan, Shiyong Wang, Ge Wang, Minghao Cheng, and Ting Li.\nMulti-agent collaboration mechanisms based on distributed online meta-learning for mass\npersonalization.Journal of Industrial Information Integration, 46:100852, 2025.\n[98] Khanh-Tung Tran, D", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 2}}, {"page_content": "Ting Li.\nMulti-agent collaboration mechanisms based on distributed online meta-learning for mass\npersonalization.Journal of Industrial Information Integration, 46:100852, 2025.\n[98] Khanh-Tung Tran, Dung Dao, Minh-Duong Nguyen, Quoc-Viet Pham, Barry O’Sullivan,\nand Hoang D Nguyen. Multi-agent collaboration mechanisms: A survey of LLMs. 2025.\n[99] Alessandro Berti, Mayssa Maatallah, Urszula Jessen, Michal Sroka, and Sonia Ayachi\nGhannouchi. Re-thinking process mining in the ai-based agents era, 2024.\n[100] Lok Hang Cheung, Likai Wang, and Dongxue Lei. Conversational, agentic AI-enhanced\narchitectural design process: three approaches to multimodal AI-enhanced early-stage\nperformative design exploration.Archit. Intell., 4(1), 2025.\n42", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 3}}, {"page_content": "[101] X. Liu et al. Agentbench: Evaluating llms as agents.arXiv [cs.AI], 2023.\n[102] C. Bird.Solving Real-World Challenges Using MEDITECH AI. Medical Information\nTechnology, Inc., 2025.\n[103] T. Esslemont and J. Thorpe. Mastercard supercharges consumer protection with gen ai,\n2024. Accessed: 13-Jul-2025.\n[104] S.R.R. Singireddy and T.U. Daim.Technology roadmap: Drone delivery – Amazon prime\nair, pages 387–412. Springer International Publishing, Cham, 2018.\n[105] V .K. Annanth, M. Abinash, and L.B. Rao. Intelligent manufacturing in the context of\nindustry 4.0: A case study of siemens industry. InJ. Phys. Conf. Ser., volume 1969, page\n012019, 2021.\n[106] S. Suh. Investigating the impact of personalized ai tutors on language learning perfor-\nmance.arXiv [cs.AI], 2025.\n[107] J. Fisher et al. Livehint: Intelligent digital support for analog learning experiences. pages\n80–89, 2020.\n[108] S. Al-E’mari, Y . Sanjalawe, and A. Al-E’mari. The role of artificial intelligence in en-\nhancing financi", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 0}}, {"page_content": "ivehint: Intelligent digital support for analog learning experiences. pages\n80–89, 2020.\n[108] S. Al-E’mari, Y . Sanjalawe, and A. Al-E’mari. The role of artificial intelligence in en-\nhancing financial decision-making and administrative efficiency: A systematic review.\nAl-Basaer Journal of Business Research, 2025.\n[109] Mahi Ratan Reddy Deva. A review of api management systems and their role in seamless\nintegration between software applications.Asian Journal of Computer Science Engineer-\ning, 10(2), 2025.\n[110] Joshua Ofoeda, Richard Boateng, and John Effah. Application programming interface\n(api) research: A review of the past to inform the future.International Journal of Enter-\nprise Information Systems, 15:76–95, 07 2019.\n[111] Lei Liu, Xun Li, Yuzhou Liu, and Huaxiao Liu. Application programming interface rec-\nommendation according to the knowledge indexed by app feature mined from app stores.\nJ. Softw. (Malden), 33(11), 2021.\n[112] Maxime Lamothe, Yann-Gaël Guéhéneuc, and Weiyi S", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 1}}, {"page_content": "programming interface rec-\nommendation according to the knowledge indexed by app feature mined from app stores.\nJ. Softw. (Malden), 33(11), 2021.\n[112] Maxime Lamothe, Yann-Gaël Guéhéneuc, and Weiyi Shang. A systematic review of api\nevolution literature.ACM Computing Surveys, 54:1–36, 10 2021.\n[113] Rishi Saripalle, Christopher Runyan, and Mitchell Russell. Using HL7 FHIR to achieve\ninteroperability in patient health record.J. Biomed. Inform., 94(103188):103188, 2019.\n[114] Miguel Pedrera-Jiménez, Noelia García-Barrio, Santiago Frid, David Moner, Diego\nBoscá-Tomás, Raimundo Lozano-Rubí, Dipak Kalra, Thomas Beale, Adolfo Muñoz-\nCarrero, and Pablo Serrano-Balazote. Can OpenEHR, ISO 13606, and HL7 FHIR\nwork together? an agnostic approach for the selection and application of electronic\nhealth record standards to the next-generation health data spaces.J. Med. Internet Res.,\n25:e48702, 2023.\n[115] Hua Zhong, Shan Jiang, and Sarfraz Khurshid. An approach for API synthesis using large\nlanguage", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 2}}, {"page_content": "record standards to the next-generation health data spaces.J. Med. Internet Res.,\n25:e48702, 2023.\n[115] Hua Zhong, Shan Jiang, and Sarfraz Khurshid. An approach for API synthesis using large\nlanguage models. 2025.\n[116] Shishir G Patil, Tianjun Zhang, Xin Wang, and Joseph E Gonzalez. Gorilla: Large lan-\nguage model connected with massive APIs. 2023.\n[117] Hana Derouiche, Zaki Brahmi, and Haithem Mazeni. Agentic AI frameworks: Architec-\ntures, protocols, and design challenges. 2025.\n[118] Agapi Rissaki, Ilias Fountalis, Nikolaos Vasiloglou, and Wolfgang Gatterbauer. Towards\nagentic schema refinement. 2024.\n43", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 3}}, {"page_content": "[119] Vaibhav Tupe and Shrinath Thube. AI agentic workflows and enterprise APIs: Adapting\nAPI architectures for the age of AI agents. 2025.\n[120] S. Raza, R. Sapkota, M. Karkee, and C. Emmanouilidis. Trism for agentic ai: A review\nof trust, risk, and security management in llm-based agentic multi-agent systems.arXiv\n[cs.AI], 2025.\n[121] O. Cárdenas, S. Falconi, E. Tusa, and A. Rodríguez. Development of a chatbot model for\nhealth telecare: Integration of langchain, embeddings with openai, and pinecone using the\nquestion answering technique.arXiv, 22(3):389–402, 2024.\n[122] Y . Bai, Z. Ding, and A. Taylor. From virtual agents to robot teams: A multi-robot frame-\nwork evaluation in high-stakes healthcare context.arXiv [cs.RO], 2025.\n[123] P. Zhang, D. Wen, G. Zhu, Q. Chen, K. Han, and Y . Shi. Collaborative edge ai inference\nover cloud-ran.IEEE Trans. Commun., 72(9):5641–5656, 2024.\n[124] S. Roychowdhury et al. Hallucination-minimized data-to-answer framework for financial\ndecision-makers", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 0}}, {"page_content": ". Collaborative edge ai inference\nover cloud-ran.IEEE Trans. Commun., 72(9):5641–5656, 2024.\n[124] S. Roychowdhury et al. Hallucination-minimized data-to-answer framework for financial\ndecision-makers.arXiv [cs.CL], 2023.\n[125] Y . Yang, Y . Tang, and K.Y . Tam. Investlm: A large language model for investment using\nfinancial domain instruction tuning.arXiv [q-fin.GN], 2023.\n[126] G. Syros, A. Suri, C. Nita-Rotaru, and A. Oprea. Saga: A security architecture for gov-\nerning ai agentic systems.arXiv [cs.CR], 2025.\n[127] K.J.K. Feng, D.W. McDonald, and A.X. Zhang. Levels of autonomy for ai agents.arXiv\n[cs.HC], 2025.\n[128] K. Tallam. Alignment, agency and autonomy in frontier ai: A systems engineering per-\nspective.arXiv [cs.CY], 2025.\n[129] H. Clatterbuck, C. Castro, and A.M. Morán. Risk alignment in agentic ai systems.arXiv\n[cs.CY], 2024.\n[130] A. Chan et al. Harms from increasingly agentic algorithmic systems. In2023 ACM\nConference on Fairness Accountability and Transparency, pages 651", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 1}}, {"page_content": "gnment in agentic ai systems.arXiv\n[cs.CY], 2024.\n[130] A. Chan et al. Harms from increasingly agentic algorithmic systems. In2023 ACM\nConference on Fairness Accountability and Transparency, pages 651–666, 2023.\n[131] Z. Tóth, R. Caruana, T. Gruber, and C. Loebbecke. The dawn of the ai robots: Towards a\nnew framework of ai robot accountability.J. Bus. Ethics, 178(4):895–916, 2022.\n[132] S. Baron. Trust, explainability and ai.Philos. Technol., 38(1), 2025.\n[133] A. Chan et al. Visibility into ai agents. InThe 2024 ACM Conference on Fairness,\nAccountability, and Transparency, 2024.\n[134] G. Papagni, J. de Pagter, S. Zafari, M. Filzmoser, and S.T. Koeszegi. Artificial agents’\nexplainability to support trust: considerations on timing and context.AI Soc., 38(2):947–\n960, 2023.\n[135] K. Singh and W. Ngu. Bias-aware agent: Enhancing fairness in ai-driven knowledge\nretrieval.arXiv [cs.IR], 2025.\n[136] S.J. Yadav. Ai bias and fairness: Ethical considerations in service marketing strategies.\nInA", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 2}}, {"page_content": "d W. Ngu. Bias-aware agent: Enhancing fairness in ai-driven knowledge\nretrieval.arXiv [cs.IR], 2025.\n[136] S.J. Yadav. Ai bias and fairness: Ethical considerations in service marketing strategies.\nInAdvances in Marketing, Customer Relationship Management, and E-Services, pages\n49–64. IGI Global, 2024.\n[137] M. Hellrigel-Holderbaum and L. Dung. Misalignment or misuse? the agi alignment\ntradeoff.arXiv [cs.CY], 2025.\n[138] J. Zhang, L. Yin, Y . Zhou, and S. Hu. Agentalign: Navigating safety alignment in the\nshift from informative to agentic large language models.arXiv [cs.CR], 2025.\n44", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 3}}, {"page_content": "[139] A. Kasirzadeh and I. Gabriel. Characterizing ai agents for alignment and governance.\narXiv [cs.CY], 2025.\n[140] A. Tiwari. Conceptualising the emergence of agentic urban ai: from automation to agency.\nUrban Inform., 4(1), 2025.\n[141] C.J. Costa and J.T. Aparicio. Exploring the societal and economic impacts of artificial\nintelligence: A scenario generation methodology.arXiv [cs.CY], 2025.\n[142] V . Lakkamraju. Agentic ai in human-ai collaboration frameworks.ESP Journal of Engi-\nneering & Technology Advancements, 5(2):114–129, 2025.\n[143] H.P. Zou et al. A call for collaborative intelligence: Why human-agent systems should\nprecede ai autonomy.arXiv [cs.AI], 2025.\n[144] U.M. Borghoff, P. Bottoni, and R. Pareschi. Human-artificial interaction in the age of\nagentic ai: a system-theoretical approach.Front. Hum. Dyn., 7, 2025.\n[145] E. Tennant, S. Hailes, and M. Musolesi. Hybrid approaches for moral value alignment in\nai agents: A manifesto.arXiv [cs.AI], 2023.\n[146] F. Rossi and N. Mat", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 0}}, {"page_content": "l approach.Front. Hum. Dyn., 7, 2025.\n[145] E. Tennant, S. Hailes, and M. Musolesi. Hybrid approaches for moral value alignment in\nai agents: A manifesto.arXiv [cs.AI], 2023.\n[146] F. Rossi and N. Mattei. Building ethically bounded ai.Proc. Conf. AAAI Artif. Intell.,\n33(01):9785–9789, 2019.\n[147] A. Reuel, A. Hardy, C. Smith, M. Lamparth, M. Hardy, and M. J. Kochenderfer. Bet-\nterbench: Assessing ai benchmarks, uncovering issues, and establishing best practices.\narXiv [cs.AI], 2024.\n[148] A. Yehudai et al. Survey on evaluation of llm-based agents.arXiv [cs.AI], 2025.\n[149] M. Zhuge et al. Agent-as-a-judge: Evaluate agents with agents.arXiv [cs.AI], 2024.\n[150] D. Moshkovich, H. Mulian, S. Zeltyn, N. Eder, I. Skarbovsky, and R. Abitbol. Beyond\nblack-box benchmarking: Observability, analytics, and optimization of agentic systems.\narXiv [cs.AI], 2025.\n[151] Eldar Sultanow, Mohammad Tehrani, Sourav Dutta, William J. Buchanan, and Muham-\nmad Salekh Khan. Quantum agents.arXiv [quant-ph], 202", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 1}}, {"page_content": "s, and optimization of agentic systems.\narXiv [cs.AI], 2025.\n[151] Eldar Sultanow, Mohammad Tehrani, Sourav Dutta, William J. Buchanan, and Muham-\nmad Salekh Khan. Quantum agents.arXiv [quant-ph], 2025.\n[152] J. Yang et al. Magma: A foundation model for multimodal ai agents.arXiv [cs.CV], 2025.\n[153] S. Agashe, J. Han, S. Gan, J. Yang, A. Li, and X.E. Wang. Agent s: An open agentic\nframework that uses computers like a human.arXiv [cs.AI], 2024.\n[154] Kun Huang, Aisha Sheriff, Venkata S. Narajala, and Itamar Habler. Agent capability\nnegotiation and binding protocol (acnbp).arXiv [cs.AI], 2025.\n[155] Yoram Bachrach, Peter Key, David Levin, Daniele Nosenzo, Gijs Overgoor, Ariel D.\nProcaccia, and Moshe Tennenholtz. Negotiating team formation using deep reinforcement\nlearning.Artificial Intelligence, 288:103356, 2020.\n[156] Petar Radanliev.The Rise of AI agents: Integrating AI, Blockchain Technologies, and\nQuantum Computing. Addison Wesley Professional, Boston, MA, 2025.\n[157] Xiaoxue Ma, C", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 2}}, {"page_content": "gence, 288:103356, 2020.\n[156] Petar Radanliev.The Rise of AI agents: Integrating AI, Blockchain Technologies, and\nQuantum Computing. Addison Wesley Professional, Boston, MA, 2025.\n[157] Xiaoxue Ma, Chen Lin, Yizhe Zhang, V olker Tresp, and Yunpu Ma. Agentic neural\nnetworks: Self-evolving multi-agent systems via textual backpropagation.arXiv [cs.LG],\n2025.\n[158] Philipp Schmidt and Sophie Loidolt. Interacting with machines: Can an artificially intel-\nligent agent be a partner?Philosophy & Technology, 36(3), 2023.\n[159] Danai Koutra et al. Towards agentic ai for science: Hypothesis generation, comprehen-\nsion, quantification, and validation.ICLR Workshop, 2025.\n45", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 3}}, {"page_content": "[160] Chris Lu, Chen Lu, Richard T. Lange, Jakob Foerster, Jeff Clune, and David Ha. The ai\nscientist: Towards fully automated open-ended scientific discovery.arXiv [cs.AI], 2024.\n[161] Sergio Cervantes, Samantha López, and Juan-Antonio Cervantes. Toward ethical cog-\nnitive architectures for the development of artificial moral agents.Cognitive Systems\nResearch, 64:117–125, 2020.\n[162] D. Thompson. Autonomous ai agents and blockchain interactions: Enabling decentralized\nautonomous organizations (daos).Journal of AI-Assisted Scientific Discovery, 4(2):73–\n79, 2024.\n[163] R. Bovo, K. Ahuja, R. Suzuki, M.D. Dogan, and M. Gonzalez-Franco. Symbiotic ai:\nAugmenting human cognition from pcs to cars.arXiv [cs.HC], 2025.\n[164] J. Samuel, R. Kashyap, Y . Samuel, and A. Pelaez. Adaptive cognitive fit: Artificial in-\ntelligence augmented management of information facets and representations.Int. J. Inf.\nManage., 65(102505):102505, 2022.\n[165] J. Wu, J. Zhu, and Y . Liu. Agentic reasoning: Reasoning ", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 0}}, {"page_content": " Artificial in-\ntelligence augmented management of information facets and representations.Int. J. Inf.\nManage., 65(102505):102505, 2022.\n[165] J. Wu, J. Zhu, and Y . Liu. Agentic reasoning: Reasoning llms with tools for the deep\nresearch.arXiv [cs.AI], 2025.\n[166] Y . Zhuang et al. Self-taught agentic long context understanding.arXiv [cs.CL], 2025.\n[167] C. Jeong. A study on the mcp x a2a framework for enhancing interoperability of llm-based\nautonomous agents.arXiv [cs.AI], 2025.\n[168] Q. Li and Y . Xie. From glue-code to protocols: A critical analysis of a2a and mcp inte-\ngration for scalable agent systems.arXiv [cs.MA], 2025.\n[169] Theodore R. Sumers, Shunyu Yao, Karthik Narasimhan, and Thomas L. Griffiths. Cogni-\ntive architectures for language agents.arXiv [cs.AI], 2023.\n[170] Octavio J. Romero, John Zimmerman, Aaron Steinfeld, and Anthony Tomasic. Syner-\ngistic integration of large language models and cognitive architectures for robust ai: An\nexploratory analysis.arXiv [cs.AI], 20", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 1}}, {"page_content": "J. Romero, John Zimmerman, Aaron Steinfeld, and Anthony Tomasic. Syner-\ngistic integration of large language models and cognitive architectures for robust ai: An\nexploratory analysis.arXiv [cs.AI], 2023.\n[171] David Shapiro, Walter Li, Marco Delaflor, and Carlos Toxtli. Conceptual framework for\nautonomous cognitive entities.arXiv [cs.HC], 2023.\n[172] Yifan Nong. Transfer learning in agentic systems: Improving cross-task knowledge ap-\nplication in ai agents.Research Square, 2025.\n[173] Hongzhi Li et al. A multi-agent framework with automated decision rule optimization for\ncross-domain misinformation detection.arXiv [cs.AI], 2025.\n[174] R. Ranjan, S. Gupta, and S.N. Singh. Fairness in agentic ai: A unified framework for\nethical and equitable multi-agent system.arXiv [cs.MA], 2025.\n[175] Vineeth Sai Narajala and Om Narayan. Securing agentic ai: A comprehensive\nthreat model and mitigation framework for generative ai agents.arXiv preprint\narXiv:2504.19956, Apr 2025. Introduces ATFAA (Advanc", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 2}}, {"page_content": "eth Sai Narajala and Om Narayan. Securing agentic ai: A comprehensive\nthreat model and mitigation framework for generative ai agents.arXiv preprint\narXiv:2504.19956, Apr 2025. Introduces ATFAA (Advanced Threat Framework for\nAutonomous AI Agents) and SHIELD mitigation framework for GenAI agents’ unique\nthreats.\n[176] Raihan Khan, Sayak Sarkar, Sainik Kumar Mahata, and Edwin Jose. Security threats in\nagentic ai system.arXiv preprint arXiv:2410.14728, Oct 2024. Explores privacy and\nsecurity threats posed by Agentic AI systems with direct database access.\n46", "metadata": {"source": "data\\agentic_ai_resource.pdf", "source_filename": "agentic_ai_resource.pdf", "chunk": 3}}]